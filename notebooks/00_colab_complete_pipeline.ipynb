{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c6da5986",
      "metadata": {
        "id": "c6da5986"
      },
      "source": [
        "# Pipeline Architecture 2.0 - Training Phase\n",
        "\n",
        "## Data Flow Overview\n",
        "\n",
        "```\n",
        "data/raw → (external processing) → data/clean\n",
        "data/clean → (00_ipynb + gemini) → data/pseudo-label  \n",
        "data/pseudo-label → data/testing + data/training\n",
        "data/clean → data/training (combined)\n",
        "HuggingFace model trained on data/training with feedback loop against gemini\n",
        "Trained models → models/saved_models\n",
        "```\n",
        "\n",
        "## Directory Structure\n",
        "\n",
        "### Data Directories\n",
        "- **`data/raw`**: Raw input data (processed externally)\n",
        "- **`data/clean`**: Cleaned/processed data from data/raw\n",
        "- **`data/pseudo-label`**: Pseudo-labeled data generated by Gemini from data/clean\n",
        "- **`data/training`**: Training data (combination of data/clean + data/pseudo-label)\n",
        "- **`data/testing`**: Testing data split from data/pseudo-label\n",
        "- **`data/actual`**: Production data for inference (used by 01_inference_pipeline.ipynb)\n",
        "\n",
        "### Model Directories\n",
        "- **`models/saved_models`**: Trained models ready for production\n",
        "- **`models/cache`**: Model cache files\n",
        "\n",
        "### Results Directories\n",
        "- **`results/predictions`**: Training predictions and evaluations\n",
        "- **`results/inference`**: Production inference results\n",
        "\n",
        "## Pipeline Components\n",
        "\n",
        "### Training Phase (This Notebook - 00_ipynb)\n",
        "1. **Environment Setup**: Install packages, configure GPU\n",
        "2. **Data Processing**: Create directory structure, load sample data\n",
        "3. **Gemini Pseudo-Labeling**: Generate high-quality labels for training\n",
        "4. **HuggingFace Training**: Train models with feedback loop against Gemini\n",
        "5. **Model Export**: Save trained models to models/saved_models\n",
        "\n",
        "### Inference Phase (01_ipynb)\n",
        "1. **Load Trained Models**: From models/saved_models\n",
        "2. **Process Production Data**: From data/actual\n",
        "3. **Generate Predictions**: Using trained pipeline\n",
        "4. **Save Results**: To results/inference\n",
        "\n",
        "## Integration Points\n",
        "- **Spam Detection**: Pipeline ready for spam detection model integration\n",
        "- **Feedback Loop**: HuggingFace model iteratively improved against Gemini predictions\n",
        "- **Production Ready**: Complete separation of training and inference phases"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b975af5e",
      "metadata": {
        "id": "b975af5e"
      },
      "source": [
        "# Review Classification Pipeline - Complete Google Colab Implementation\n",
        "\n",
        "This notebook implements the complete review classification pipeline for detecting Google review policy violations, fully configured for Google Colab.\n",
        "\n",
        "## Pipeline Overview\n",
        "\n",
        "### Phase 1: Environment Setup and Data Structure\n",
        "- Install all required packages (transformers, torch, google-generativeai, etc.)\n",
        "- Create proper directory structure (data/clean, data/pseudo-label, etc.)\n",
        "- Load sample data for demonstration\n",
        "\n",
        "### Phase 2: Core Pipeline Components\n",
        "- **Ollama Pipeline**: Local LLM classification (for reference, not runnable in Colab)\n",
        "- **HuggingFace Pipeline**: Zero-shot classification using pre-trained models\n",
        "- **Gemini Pseudo-Labeling**: High-quality label generation for training data\n",
        "- **Ensemble Method**: Combines multiple approaches for best results\n",
        "\n",
        "### Phase 3: Future Spam Detection Integration\n",
        "- Pipeline output will be piped into a spam detection model\n",
        "- Structured JSON output format for downstream processing\n",
        "- Confidence scoring for reliable filtering\n",
        "\n",
        "### Phase 4: Evaluation and Analysis\n",
        "- Comprehensive performance metrics\n",
        "- Policy category accuracy assessment\n",
        "- Model comparison and improvement recommendations\n",
        "\n",
        "**Key Features:**\n",
        "- **Policy Categories**: No_Ads, Irrelevant, Rant_No_Visit detection\n",
        "- **Zero Setup**: Everything configured for Google Colab\n",
        "- **Extensible**: Ready for spam detection integration\n",
        "- **Production Ready**: Structured output and comprehensive evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5462d932",
      "metadata": {
        "id": "5462d932"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f35169",
      "metadata": {
        "id": "96f35169",
        "outputId": "c480cf9d-ce53-40ab-8c6b-631c38a236e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m✅ Core packages installed successfully!\n",
            "Using device: cpu\n",
            "Using CPU - models will run slower but still functional\n",
            "Environment configured for optimal performance\n"
          ]
        }
      ],
      "source": [
        "# Install required packages for the complete pipeline\n",
        "!pip install -q transformers==4.43.3 torch pandas scikit-learn\n",
        "!pip install -q google-generativeai tqdm datasets accelerate\n",
        "!pip install -q ipywidgets matplotlib seaborn wordcloud\n",
        "\n",
        "print(\"✅ Core packages installed successfully!\")\n",
        "\n",
        "# Check GPU availability and setup device\n",
        "import torch\n",
        "import os\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"Using CPU - models will run slower but still functional\")\n",
        "\n",
        "# Set environment for optimal performance\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Avoid warnings\n",
        "print(\"Environment configured for optimal performance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d42837",
      "metadata": {
        "id": "77d42837"
      },
      "source": [
        "## 2. Project Structure Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0558d7e",
      "metadata": {
        "id": "c0558d7e",
        "outputId": "bae96bfd-92d8-40b8-bd31-0c85b8d68945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Complete directory structure created!\n",
            "Created 20 directories\n",
            "✅ data/clean\n",
            "✅ data/pseudo-label\n",
            "✅ data/sample\n",
            "✅ results/predictions\n",
            "\n",
            "Directory structure matches production pipeline!\n"
          ]
        }
      ],
      "source": [
        "# Create complete directory structure matching the actual pipeline\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Create all necessary directories (matching actual pipeline structure)\n",
        "directories = [\n",
        "    # Source code structure\n",
        "    'src/config', 'src/core', 'src/pseudo_labelling', 'src/pipeline', 'src/integration',\n",
        "\n",
        "    # Data directories (matching actual structure)\n",
        "    'data/raw',           # For raw input data\n",
        "    'data/clean',         # For cleaned/processed data (from data/raw)\n",
        "    'data/pseudo-label',  # For pseudo-labeled data from Gemini (from data/clean)\n",
        "    'data/training',      # For training data split (from data/clean + data/pseudo-label)\n",
        "    'data/testing',       # For testing data split (from data/pseudo-label)\n",
        "    'data/actual',        # For actual production data to be processed by 01_inference_pipeline.ipynb\n",
        "    'data/sample',        # For sample data\n",
        "\n",
        "    # Results directories\n",
        "    'results/predictions',   # All predictions\n",
        "    'results/evaluations',   # For evaluation results\n",
        "    'results/reports',       # For generated reports\n",
        "\n",
        "    # Other directories\n",
        "    'models/saved_models',   # For trained models\n",
        "    'models/cache',          # For model cache\n",
        "    'logs/pipeline_logs',    # For pipeline logs\n",
        "    'prompts',               # Prompt engineering\n",
        "    'docs'                   # Documentation\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    # Create __init__.py files for Python packages\n",
        "    if directory.startswith('src/'):\n",
        "        with open(f'{directory}/__init__.py', 'w') as f:\n",
        "            f.write('# Review Classification Pipeline Package\\n')\n",
        "\n",
        "print(\"✅ Complete directory structure created!\")\n",
        "print(f\"Created {len(directories)} directories\")\n",
        "\n",
        "# Verify critical directories exist\n",
        "critical_dirs = ['data/clean', 'data/pseudo-label', 'data/sample', 'results/predictions']\n",
        "for dir_name in critical_dirs:\n",
        "    if os.path.exists(dir_name):\n",
        "        print(f\"✅ {dir_name}\")\n",
        "    else:\n",
        "        print(f\"❌ {dir_name} - MISSING!\")\n",
        "\n",
        "print(\"\\nDirectory structure matches production pipeline!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc18cdbb",
      "metadata": {
        "id": "bc18cdbb"
      },
      "source": [
        "## 3. Sample Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8856980d",
      "metadata": {
        "id": "8856980d",
        "outputId": "78c1855e-4a1f-470c-9377-1cb9b02994f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Production sample data loaded!\n",
            "\n",
            "Sample Data Overview:\n",
            " id                                                             text gold_label gold_category\n",
            "  1          Use my promo code EAT10 for 10% off! DM me on WhatsApp.     REJECT        No_Ads\n",
            "  2     Great laksa; broth was rich and staff friendly. Will return.    APPROVE          None\n",
            "  3 Crypto is the future. Buy BTC now! Nothing to do with this cafe.     REJECT    Irrelevant\n",
            "  4                          Overpriced scammers. Society is doomed.     REJECT Rant_No_Visit\n",
            "  5 Visited on 18 Aug, ordered set A; cashier fixed a double-charge.    APPROVE          None\n",
            "\n",
            "Label Distribution:\n",
            "APPROVE: 2 reviews\n",
            "REJECT:  3 reviews\n",
            "\n",
            "Category Distribution:\n",
            "None: 2 reviews\n",
            "No_Ads: 1 reviews\n",
            "Irrelevant: 1 reviews\n",
            "Rant_No_Visit: 1 reviews\n",
            "\n",
            "This data demonstrates all policy violation types:\n",
            "• No_Ads: Promotional codes and contact solicitation\n",
            "• Irrelevant: Off-topic content unrelated to business\n",
            "• Rant_No_Visit: Generic negative comments without visit evidence\n",
            "• None: Legitimate reviews that should be approved\n"
          ]
        }
      ],
      "source": [
        "# Load actual sample data from the production pipeline\n",
        "sample_data = {\n",
        "    'id': [1, 2, 3, 4, 5],\n",
        "    'text': [\n",
        "        \"Use my promo code EAT10 for 10% off! DM me on WhatsApp.\",\n",
        "        \"Great laksa; broth was rich and staff friendly. Will return.\",\n",
        "        \"Crypto is the future. Buy BTC now! Nothing to do with this cafe.\",\n",
        "        \"Overpriced scammers. Society is doomed.\",\n",
        "        \"Visited on 18 Aug, ordered set A; cashier fixed a double-charge.\"\n",
        "    ],\n",
        "    'gold_label': ['REJECT', 'APPROVE', 'REJECT', 'REJECT', 'APPROVE'],\n",
        "    'gold_category': ['No_Ads', 'None', 'Irrelevant', 'Rant_No_Visit', 'None']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(sample_data)\n",
        "df.to_csv('data/sample/sample_reviews.csv', index=False)\n",
        "\n",
        "print(\"✅ Production sample data loaded!\")\n",
        "print(\"\\nSample Data Overview:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(f\"\\nLabel Distribution:\")\n",
        "print(f\"APPROVE: {len(df[df['gold_label'] == 'APPROVE'])} reviews\")\n",
        "print(f\"REJECT:  {len(df[df['gold_label'] == 'REJECT'])} reviews\")\n",
        "\n",
        "print(f\"\\nCategory Distribution:\")\n",
        "for category in df['gold_category'].value_counts().index:\n",
        "    count = df['gold_category'].value_counts()[category]\n",
        "    print(f\"{category}: {count} reviews\")\n",
        "\n",
        "print(f\"\\nThis data demonstrates all policy violation types:\")\n",
        "print(\"• No_Ads: Promotional codes and contact solicitation\")\n",
        "print(\"• Irrelevant: Off-topic content unrelated to business\")\n",
        "print(\"• Rant_No_Visit: Generic negative comments without visit evidence\")\n",
        "print(\"• None: Legitimate reviews that should be approved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1014facd",
      "metadata": {
        "id": "1014facd"
      },
      "source": [
        "## 4. Configuration Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97baccb",
      "metadata": {
        "id": "a97baccb",
        "outputId": "df8b6a8e-4295-459d-c597-300565d14185",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration created matching production pipeline!\n",
            "Data directory: data/sample\n",
            "HF Zero-shot model: facebook/bart-large-mnli\n",
            "Ensemble tau: 0.55\n",
            "Predictions output: results/predictions/predictions_hf.csv\n"
          ]
        }
      ],
      "source": [
        "# Create configuration classes matching the actual pipeline\n",
        "config_code = '''\n",
        "\"\"\"\n",
        "Pipeline Configuration Classes - Matching Production Structure\n",
        "\"\"\"\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional\n",
        "import os\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Configuration for model settings\"\"\"\n",
        "    # HuggingFace models (matching actual pipeline)\n",
        "    hf_sentiment_model: str = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "    hf_toxicity_model: str = \"unitary/toxic-bert\"\n",
        "    hf_zero_shot_model: str = \"facebook/bart-large-mnli\"\n",
        "\n",
        "    # Gemini configuration\n",
        "    gemini_model: str = \"gemini-2.5-flash-lite\"\n",
        "\n",
        "    # Confidence thresholds (matching actual pipeline)\n",
        "    sentiment_threshold: float = 0.7\n",
        "    toxicity_threshold: float = 0.5\n",
        "    zero_shot_threshold: float = 0.7\n",
        "    ensemble_tau: float = 0.55\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    \"\"\"Configuration for data paths and settings\"\"\"\n",
        "    data_dir: str = \"data\"\n",
        "    raw_data_dir: str = \"data/raw\"\n",
        "    processed_data_dir: str = \"data/clean\"  # Matches actual structure\n",
        "    sample_data_dir: str = \"data/sample\"\n",
        "    pseudo_label_dir: str = \"data/pseudo-label\"  # Matches actual structure\n",
        "    training_dir: str = \"data/training\"\n",
        "    testing_dir: str = \"data/testing\"\n",
        "\n",
        "    # Default input file\n",
        "    sample_reviews_file: str = \"data/sample/sample_reviews.csv\"\n",
        "\n",
        "@dataclass\n",
        "class OutputConfig:\n",
        "    \"\"\"Configuration for output paths\"\"\"\n",
        "    results_dir: str = \"results\"\n",
        "    predictions_dir: str = \"results/predictions\"\n",
        "    evaluations_dir: str = \"results/evaluations\"\n",
        "    reports_dir: str = \"results/reports\"\n",
        "\n",
        "    # Default output files (matching actual pipeline)\n",
        "    hf_predictions: str = \"results/predictions/predictions_hf.csv\"\n",
        "    ensemble_predictions: str = \"results/predictions/predictions_ens.csv\"\n",
        "\n",
        "@dataclass\n",
        "class PipelineConfig:\n",
        "    \"\"\"Main pipeline configuration combining all components\"\"\"\n",
        "    model: ModelConfig = field(default_factory=ModelConfig)\n",
        "    data: DataConfig = field(default_factory=DataConfig)\n",
        "    output: OutputConfig = field(default_factory=OutputConfig)\n",
        "\n",
        "    # Gemini configuration\n",
        "    gemini_api_key: str = \"\"\n",
        "\n",
        "    # Pipeline settings\n",
        "    batch_size: int = 32\n",
        "    max_workers: int = 4\n",
        "    cache_predictions: bool = True\n",
        "    verbose_logging: bool = True\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Create directories if they don't exist\"\"\"\n",
        "        directories = [\n",
        "            self.data.raw_data_dir,\n",
        "            self.data.processed_data_dir,\n",
        "            self.data.sample_data_dir,\n",
        "            self.data.pseudo_label_dir,\n",
        "            self.data.training_dir,\n",
        "            self.data.testing_dir,\n",
        "            self.output.predictions_dir,\n",
        "            self.output.evaluations_dir,\n",
        "            self.output.reports_dir\n",
        "        ]\n",
        "\n",
        "        for directory in directories:\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Global configuration instance\n",
        "config = PipelineConfig()\n",
        "'''\n",
        "\n",
        "with open('src/config/pipeline_config.py', 'w') as f:\n",
        "    f.write(config_code)\n",
        "\n",
        "print(\"✅ Configuration created matching production pipeline!\")\n",
        "\n",
        "# Test configuration\n",
        "exec(config_code)\n",
        "test_config = PipelineConfig()\n",
        "print(f\"Data directory: {test_config.data.sample_data_dir}\")\n",
        "print(f\"HF Zero-shot model: {test_config.model.hf_zero_shot_model}\")\n",
        "print(f\"Ensemble tau: {test_config.model.ensemble_tau}\")\n",
        "print(f\"Predictions output: {test_config.output.hf_predictions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "becf61f4",
      "metadata": {
        "id": "becf61f4"
      },
      "source": [
        "## 5. Constants and Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b648a5",
      "metadata": {
        "id": "f5b648a5",
        "outputId": "94d98e0c-39a3-43c1-dc16-9df1f8a453eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Constants and prompts created matching production pipeline!\n",
            "Policy categories: ['No_Ads', 'Irrelevant', 'Rant_No_Visit', 'None']\n",
            "Zero-shot model: facebook/bart-large-mnli\n",
            "Default confidence threshold: 0.55\n",
            "Zero-shot labels configured: 4 categories\n"
          ]
        }
      ],
      "source": [
        "# Create constants and prompts matching the actual pipeline\n",
        "constants_code = '''\n",
        "\"\"\"\n",
        "Core Constants - Matching Production Pipeline\n",
        "\"\"\"\n",
        "\n",
        "# Policy Categories (matching actual pipeline)\n",
        "POLICY_CATEGORIES = {\n",
        "    'NO_ADS': 'No_Ads',\n",
        "    'IRRELEVANT': 'Irrelevant',\n",
        "    'RANT_NO_VISIT': 'Rant_No_Visit',\n",
        "    'NONE': 'None'\n",
        "}\n",
        "\n",
        "# Label Types (matching actual pipeline)\n",
        "LABELS = {\n",
        "    'APPROVE': 'APPROVE',\n",
        "    'REJECT': 'REJECT'\n",
        "}\n",
        "\n",
        "# Default Models (matching actual pipeline)\n",
        "DEFAULT_MODELS = {\n",
        "    'SENTIMENT': \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    'TOXIC': \"unitary/toxic-bert\",\n",
        "    'ZERO_SHOT': \"facebook/bart-large-mnli\",\n",
        "    'GEMINI_DEFAULT': \"gemini-2.5-flash-lite\"\n",
        "}\n",
        "\n",
        "# Zero-shot Classification Labels (matching actual pipeline)\n",
        "ZERO_SHOT_LABELS = [\n",
        "    \"an advertisement or promotional solicitation for this business (promo code, referral, links, contact to buy)\",\n",
        "    \"off-topic or unrelated to this business (e.g., politics, crypto, chain messages, personal stories not about this place)\",\n",
        "    \"a generic negative rant about this business without evidence of a visit (short insults, 'scam', 'overpriced', 'worst ever')\",\n",
        "    \"a relevant on-topic description of a visit or experience at this business\"\n",
        "]\n",
        "\n",
        "# Mapping zero-shot labels to policy categories\n",
        "ZERO_SHOT_TO_POLICY = {\n",
        "    ZERO_SHOT_LABELS[0]: POLICY_CATEGORIES['NO_ADS'],\n",
        "    ZERO_SHOT_LABELS[1]: POLICY_CATEGORIES['IRRELEVANT'],\n",
        "    ZERO_SHOT_LABELS[2]: POLICY_CATEGORIES['RANT_NO_VISIT'],\n",
        "    ZERO_SHOT_LABELS[3]: POLICY_CATEGORIES['NONE']\n",
        "}\n",
        "\n",
        "# Confidence Thresholds\n",
        "CONFIDENCE_THRESHOLDS = {\n",
        "    'HIGH': 0.8,\n",
        "    'MEDIUM': 0.6,\n",
        "    'LOW': 0.4,\n",
        "    'DEFAULT': 0.55\n",
        "}\n",
        "'''\n",
        "\n",
        "with open('src/core/constants.py', 'w') as f:\n",
        "    f.write(constants_code)\n",
        "\n",
        "# Create prompt templates (matching actual pipeline)\n",
        "prompts_code = '''\n",
        "\"\"\"\n",
        "Policy Prompts - Matching Production Pipeline\n",
        "\"\"\"\n",
        "\n",
        "# JSON schema all prompts must return\n",
        "TEMPLATE_JSON = \"\"\"Return ONLY JSON with no extra text:\n",
        "{\"label\":\"<APPROVE|REJECT>\",\"category\":\"<No_Ads|Irrelevant|Rant_No_Visit|None>\",\n",
        " \"rationale\":\"<short>\",\"confidence\":<0.0-1.0>,\n",
        " \"flags\":{\"links\":false,\"coupon\":false,\"visit_claimed\":false}}\n",
        "\"\"\"\n",
        "\n",
        "# ===== 1) NO ADS / PROMOTIONAL =====\n",
        "NO_ADS_SYSTEM = \"\"\"You are a content policy checker for location reviews.\n",
        "If this specific policy does NOT clearly apply, return APPROVE with category \"None\" and confidence 0.0. Do not reject for other policies.\n",
        "Reject ONLY if the review contains clear advertising or promotional solicitation:\n",
        "- referral/promo/coupon codes, price lists, booking/ordering links, contact-for-order (DM me / WhatsApp / Telegram / email / call), affiliate pitches.\n",
        "Do NOT mark generic off-topic content (e.g., crypto/politics) as Ads unless it includes explicit solicitation to buy or contact.\n",
        "Approve normal experiences even if positive or mentioning 'cheap' or 'good deal'.\n",
        "Output the required JSON only.\n",
        "\"\"\"\n",
        "\n",
        "# ===== 2) IRRELEVANT CONTENT =====\n",
        "IRRELEVANT_SYSTEM = \"\"\"You are checking ONLY for the 'Irrelevant' policy.\n",
        "\n",
        "Decision rule (mutually exclusive):\n",
        "- If this specific policy does NOT clearly apply, return APPROVE with category \"None\" and confidence 0.0.\n",
        "- Do not reject for other policies (e.g., Ads or Rant_No_Visit).\n",
        "\n",
        "Reject as Irrelevant when the text is off-topic and unrelated to THIS venue/service:\n",
        "- unrelated politics/news/crypto hype/chain messages/personal stories\n",
        "- generic advice not tied to this place (e.g., 'buy BTC now', 'vote X'), etc.\n",
        "- content about another business or location without discussing this one\n",
        "\n",
        "Return ONLY JSON with fields: label, category, rationale, confidence (0.0–1.0), flags.\n",
        "\"\"\"\n",
        "\n",
        "# ===== 3) RANTS WITHOUT VISIT =====\n",
        "RANT_NO_VISIT_SYSTEM = \"\"\"Reject generic rants or accusations clearly targeting THIS place but with no evidence of a visit.\n",
        "These rants are often:\n",
        "- Short and emotional (e.g., 'Terrible place', 'Worst ever', 'Overpriced scammers')\n",
        "- Broad accusations ('scam', 'rip-off', 'fraud')\n",
        "- Negative judgments about pricing, quality, or character of the venue\n",
        "Reject them even if the reviewer does not explicitly say 'this place/restaurant' — assume negativity is directed at the business being reviewed.\n",
        "Approve only if the reviewer provides concrete evidence of a visit (date, food ordered, staff interaction).\n",
        "Output JSON only.\n",
        "\"\"\"\n",
        "\n",
        "def build_prompt(system_text: str, review_text: str, fewshots):\n",
        "    demo = \"\\\\n\\\\n\".join(\n",
        "        [f\"Review:\\\\n{r}\\\\nExpected JSON:\\\\n{j}\" for r,j in fewshots]\n",
        "    )\n",
        "    return f\"\"\"{system_text}\n",
        "\n",
        "{TEMPLATE_JSON}\n",
        "\n",
        "{demo}\n",
        "\n",
        "Now classify this review. Return ONLY JSON.\n",
        "\n",
        "Review:\n",
        "{review_text}\n",
        "\"\"\"\n",
        "'''\n",
        "\n",
        "with open('prompts/policy_prompts.py', 'w') as f:\n",
        "    f.write(prompts_code)\n",
        "\n",
        "print(\"✅ Constants and prompts created matching production pipeline!\")\n",
        "\n",
        "# Test constants\n",
        "exec(constants_code)\n",
        "print(f\"Policy categories: {list(POLICY_CATEGORIES.values())}\")\n",
        "print(f\"Zero-shot model: {DEFAULT_MODELS['ZERO_SHOT']}\")\n",
        "print(f\"Default confidence threshold: {CONFIDENCE_THRESHOLDS['DEFAULT']}\")\n",
        "print(f\"Zero-shot labels configured: {len(ZERO_SHOT_LABELS)} categories\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6015eaed",
      "metadata": {
        "id": "6015eaed"
      },
      "source": [
        "## 6. Gemini API Configuration and Pseudo-Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33aa5b43",
      "metadata": {
        "id": "33aa5b43",
        "outputId": "14bf9435-b6c8-42f8-b862-bbff48faf22d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab secrets not found: Secret GEMINI_API_KEY does not exist.\n",
            "Please enter your Gemini API key manually:\n",
            "\n",
            "Instructions:\n",
            "1. Go to: https://aistudio.google.com/app/apikey\n",
            "2. Click 'Create API Key'\n",
            "3. Copy the key\n",
            "\n",
            "Enter your Gemini API key: AIzaSyB3Ga_EcYK6l85ze-0cH-uy5-DA-yD58dE\n",
            "✅ Gemini API test successful!\n",
            "   Source: manual\n",
            "   Model: gemini-2.5-flash-lite\n",
            "\n",
            "Configuration Summary:\n",
            "   Gemini Available: ✅ Yes\n",
            "   HuggingFace: ✅ Ready\n",
            "   Pipeline Mode: Full\n",
            "\n",
            "============================================================\n",
            "GENERATING TRAINING DATA WITH PSEUDO-LABELS\n",
            "============================================================\n",
            "Created 20 diverse reviews for pseudo-labeling\n",
            "\n",
            "Starting Gemini pseudo-labeling for training data...\n",
            "Generating pseudo-labels for training data...\n",
            "Confidence threshold: 0.7\n",
            "Max labels to generate: 20\n",
            "Processing 20 reviews...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating pseudo-labels:   0%|          | 0/20 [00:00<?, ?it/s]WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 844.65ms\n",
            "Generating pseudo-labels:   5%|▌         | 1/20 [00:00<00:18,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 588.96ms\n",
            "Generating pseudo-labels:  10%|█         | 2/20 [00:01<00:14,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 766.18ms\n",
            "Generating pseudo-labels:  15%|█▌        | 3/20 [00:02<00:14,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 688.54ms\n",
            "Generating pseudo-labels:  20%|██        | 4/20 [00:03<00:13,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 633.49ms\n",
            "Generating pseudo-labels:  25%|██▌       | 5/20 [00:04<00:11,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "   Processed 5 reviews, generated 0 high-confidence labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 708.92ms\n",
            "Generating pseudo-labels:  30%|███       | 6/20 [00:04<00:11,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 684.64ms\n",
            "Generating pseudo-labels:  35%|███▌      | 7/20 [00:05<00:10,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 736.55ms\n",
            "Generating pseudo-labels:  40%|████      | 8/20 [00:06<00:09,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 607.67ms\n",
            "Generating pseudo-labels:  45%|████▌     | 9/20 [00:07<00:08,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 810.40ms\n",
            "Generating pseudo-labels:  50%|█████     | 10/20 [00:08<00:08,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "   Processed 10 reviews, generated 0 high-confidence labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 607.41ms\n",
            "Generating pseudo-labels:  55%|█████▌    | 11/20 [00:08<00:07,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 709.09ms\n",
            "Generating pseudo-labels:  60%|██████    | 12/20 [00:09<00:06,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 633.72ms\n",
            "Generating pseudo-labels:  65%|██████▌   | 13/20 [00:10<00:05,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 837.13ms\n",
            "Generating pseudo-labels:  70%|███████   | 14/20 [00:11<00:04,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 583.82ms\n",
            "Generating pseudo-labels:  75%|███████▌  | 15/20 [00:12<00:03,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "   Processed 15 reviews, generated 0 high-confidence labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 811.04ms\n",
            "Generating pseudo-labels:  80%|████████  | 16/20 [00:12<00:03,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.04ms\n",
            "Generating pseudo-labels:  85%|████████▌ | 17/20 [00:13<00:02,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 734.49ms\n",
            "Generating pseudo-labels:  90%|█████████ | 18/20 [00:14<00:01,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.48ms\n",
            "Generating pseudo-labels:  95%|█████████▌| 19/20 [00:15<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 734.21ms\n",
            "Generating pseudo-labels: 100%|██████████| 20/20 [00:16<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "   Processed 20 reviews, generated 0 high-confidence labels\n",
            "❌ No high-confidence pseudo-labels generated\n",
            "Try lowering confidence threshold or checking API responses\n",
            "❌ No pseudo-labels generated - will use pre-trained models only\n",
            "\n",
            "Training data preparation: ❌ Skipped\n",
            "Ready for HuggingFace model training: ⚠️ Pre-trained only\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Gemini API Key Setup and Pseudo-Labeling Implementation\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Option A: Try Colab secrets first (recommended)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    print(\"✅ Gemini API key loaded from Colab secrets\")\n",
        "    api_source = \"secrets\"\n",
        "except Exception as e:\n",
        "    print(f\"Colab secrets not found: {e}\")\n",
        "\n",
        "    # Option B: Manual input fallback\n",
        "    print(\"Please enter your Gemini API key manually:\")\n",
        "    print(\"\")\n",
        "    print(\"Instructions:\")\n",
        "    print(\"1. Go to: https://aistudio.google.com/app/apikey\")\n",
        "    print(\"2. Click 'Create API Key'\")\n",
        "    print(\"3. Copy the key\")\n",
        "    print(\"\")\n",
        "\n",
        "    GEMINI_API_KEY = input(\"Enter your Gemini API key: \").strip()\n",
        "    api_source = \"manual\"\n",
        "\n",
        "# Configure Gemini\n",
        "if GEMINI_API_KEY:\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "    # Test the API\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
        "        test_response = model.generate_content(\"Test: Say 'API working'\")\n",
        "        print(f\"✅ Gemini API test successful!\")\n",
        "        print(f\"   Source: {api_source}\")\n",
        "        print(f\"   Model: gemini-2.5-flash-lite\")\n",
        "        gemini_available = True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Gemini test failed: {e}\")\n",
        "        print(\"Check your API key and quota limits\")\n",
        "        gemini_available = False\n",
        "else:\n",
        "    print(\"No API key provided\")\n",
        "    print(\"Pipeline will run without Gemini pseudo-labeling\")\n",
        "    print(\"HuggingFace components will still work perfectly!\")\n",
        "    gemini_available = False\n",
        "\n",
        "print(f\"\\nConfiguration Summary:\")\n",
        "print(f\"   Gemini Available: {'✅ Yes' if gemini_available else '❌ No'}\")\n",
        "print(f\"   HuggingFace: ✅ Ready\")\n",
        "print(f\"   Pipeline Mode: {'Full' if gemini_available else 'HuggingFace Only'}\")\n",
        "\n",
        "# Gemini Pseudo-Labeling Implementation (for Training Data Generation)\n",
        "def classify_with_gemini(text: str, model_name=\"gemini-2.0-flash-exp\"):\n",
        "    \"\"\"Generate pseudo-labels using Gemini for training data\"\"\"\n",
        "    try:\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "\n",
        "        # Enhanced prompt for better pseudo-labeling\n",
        "        prompt = f\"\"\"\n",
        "You are a Google review policy expert. Classify this review and provide a JSON response.\n",
        "\n",
        "Review: \"{text}\"\n",
        "\n",
        "Policy Categories:\n",
        "- No_Ads: Contains advertisements, promotional content, promo codes, contact information\n",
        "- Irrelevant: Off-topic content (politics, crypto, unrelated businesses)\n",
        "- Rant_No_Visit: Generic negative rants without evidence of visiting\n",
        "- None: Legitimate review about an actual visit/experience\n",
        "\n",
        "Respond with JSON only:\n",
        "{{\"label\": \"APPROVE\" or \"REJECT\", \"category\": \"policy_name\", \"confidence\": 0.0-1.0, \"rationale\": \"brief_explanation\"}}\n",
        "\"\"\"\n",
        "\n",
        "        response = model.generate_content(prompt)\n",
        "        response_text = response.text.strip()\n",
        "\n",
        "        # Try to parse JSON response\n",
        "        if response_text.startswith('```json'):\n",
        "            response_text = response_text.replace('```json', '').replace('```', '').strip()\n",
        "        elif response_text.startswith('```'):\n",
        "            response_text = response_text.replace('```', '').strip()\n",
        "\n",
        "        try:\n",
        "            result = json.loads(response_text)\n",
        "\n",
        "            # Validate required fields\n",
        "            if all(key in result for key in ['label', 'category', 'confidence']):\n",
        "                return {\n",
        "                    \"label\": result['label'],\n",
        "                    \"category\": result['category'],\n",
        "                    \"confidence\": float(result['confidence']),\n",
        "                    \"rationale\": result.get('rationale', 'Gemini classification')\n",
        "                }\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "        # Fallback parsing if JSON fails\n",
        "        if 'REJECT' in response_text.upper():\n",
        "            # Try to extract category\n",
        "            if 'No_Ads' in response_text or 'advertisement' in response_text.lower():\n",
        "                category = 'No_Ads'\n",
        "            elif 'Irrelevant' in response_text or 'off-topic' in response_text.lower():\n",
        "                category = 'Irrelevant'\n",
        "            elif 'Rant_No_Visit' in response_text or 'rant' in response_text.lower():\n",
        "                category = 'Rant_No_Visit'\n",
        "            else:\n",
        "                category = 'No_Ads'  # Default\n",
        "\n",
        "            return {\"label\": \"REJECT\", \"category\": category, \"confidence\": 0.7, \"rationale\": \"Parsed from text\"}\n",
        "        else:\n",
        "            return {\"label\": \"APPROVE\", \"category\": \"None\", \"confidence\": 0.7, \"rationale\": \"Parsed from text\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini API error: {e}\")\n",
        "        return {\"label\": \"APPROVE\", \"category\": \"None\", \"confidence\": 0.0, \"rationale\": f\"API error: {e}\"}\n",
        "\n",
        "def generate_pseudo_labels_with_gemini(unlabeled_df, confidence_threshold=0.8, max_labels=50):\n",
        "    \"\"\"Generate high-quality pseudo-labels for training data\"\"\"\n",
        "    if not gemini_available:\n",
        "        print(\"❌ Gemini not available for pseudo-labeling\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"Generating pseudo-labels for training data...\")\n",
        "    print(f\"Confidence threshold: {confidence_threshold}\")\n",
        "    print(f\"Max labels to generate: {max_labels}\")\n",
        "\n",
        "    pseudo_labels = []\n",
        "    processed_count = 0\n",
        "\n",
        "    print(f\"Processing {min(len(unlabeled_df), max_labels)} reviews...\")\n",
        "\n",
        "    for _, row in tqdm(unlabeled_df.iterrows(), total=min(len(unlabeled_df), max_labels), desc=\"Generating pseudo-labels\"):\n",
        "        if processed_count >= max_labels:\n",
        "            break\n",
        "\n",
        "        text = str(row['text'])\n",
        "        result = classify_with_gemini(text)\n",
        "\n",
        "        # Only include high-confidence predictions for training\n",
        "        if result['confidence'] >= confidence_threshold:\n",
        "            pseudo_labels.append({\n",
        "                'id': row.get('id', processed_count + 100),\n",
        "                'text': text,\n",
        "                'pred_label': result['label'],\n",
        "                'pred_category': result['category'],\n",
        "                'confidence': result['confidence'],\n",
        "                'rationale': result['rationale'],\n",
        "                'source': 'gemini_pseudo'\n",
        "            })\n",
        "\n",
        "        processed_count += 1\n",
        "        time.sleep(0.1)  # Rate limiting for API\n",
        "\n",
        "        # Progress update\n",
        "        if processed_count % 5 == 0:\n",
        "            print(f\"   Processed {processed_count} reviews, generated {len(pseudo_labels)} high-confidence labels\")\n",
        "\n",
        "    pseudo_df = pd.DataFrame(pseudo_labels)\n",
        "\n",
        "    if len(pseudo_df) > 0:\n",
        "        # Save to proper directory for training\n",
        "        output_path = 'data/pseudo-label/gemini_pseudo_labels.csv'\n",
        "        pseudo_df.to_csv(output_path, index=False)\n",
        "\n",
        "        print(f\"✅ Generated {len(pseudo_df)} high-confidence pseudo-labels for training\")\n",
        "        print(f\"Saved to: {output_path}\")\n",
        "        print(f\"Label distribution: {pseudo_df['pred_label'].value_counts().to_dict()}\")\n",
        "        print(f\"Category distribution: {pseudo_df['pred_category'].value_counts().to_dict()}\")\n",
        "\n",
        "        # Quality metrics\n",
        "        avg_confidence = pseudo_df['confidence'].mean()\n",
        "        print(f\"Average confidence: {avg_confidence:.3f}\")\n",
        "\n",
        "        return pseudo_df\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No high-confidence pseudo-labels generated\")\n",
        "        print(\"Try lowering confidence threshold or checking API responses\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Generate Training Data with Pseudo-Labels\n",
        "if gemini_available:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GENERATING TRAINING DATA WITH PSEUDO-LABELS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create diverse unlabeled data for pseudo-labeling\n",
        "    unlabeled_data = {\n",
        "        'id': list(range(101, 121)),\n",
        "        'text': [\n",
        "            \"Amazing food and service, definitely coming back!\",\n",
        "            \"Visit our website for exclusive deals and discounts - use code SAVE20\",\n",
        "            \"The worst experience ever, everything was terrible, total scam\",\n",
        "            \"Staff was friendly, food was fresh and tasty, good value for money\",\n",
        "            \"This place is overpriced, never going back, waste of money\",\n",
        "            \"Great atmosphere, perfect for family dinner, ordered the set meal and dessert\",\n",
        "            \"Follow my Instagram @foodie123 for more reviews and promos\",\n",
        "            \"Bitcoin is going to the moon! Buy now before it's too late!\",\n",
        "            \"Had the chicken rice here yesterday, portion was generous and taste was authentic\",\n",
        "            \"DM me for discount codes! Also selling crypto courses online\",\n",
        "            \"Terrible service, rude staff, food was cold when it arrived\",\n",
        "            \"The laksa here reminds me of my grandmother's cooking, very nostalgic\",\n",
        "            \"Check out my YouTube channel for food reviews and crypto tips\",\n",
        "            \"Went here for lunch with colleagues, everyone enjoyed their meals\",\n",
        "            \"Overpriced tourist trap, locals know better places nearby\",\n",
        "            \"Made reservation for 6pm, got seated immediately, excellent service throughout\",\n",
        "            \"Politics in this country is corrupt, restaurants like this are part of the problem\",\n",
        "            \"Their signature dish was perfectly seasoned, will definitely recommend to friends\",\n",
        "            \"Worst restaurant in Singapore, total ripoff, avoid at all costs\",\n",
        "            \"Celebrated my birthday here last week, staff even brought out a cake\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    unlabeled_df = pd.DataFrame(unlabeled_data)\n",
        "    print(f\"Created {len(unlabeled_df)} diverse reviews for pseudo-labeling\")\n",
        "\n",
        "    # Generate pseudo-labels for training\n",
        "    print(f\"\\nStarting Gemini pseudo-labeling for training data...\")\n",
        "    pseudo_labels_df = generate_pseudo_labels_with_gemini(\n",
        "        unlabeled_df,\n",
        "        confidence_threshold=0.7,  # Lower threshold for more training data\n",
        "        max_labels=20\n",
        "    )\n",
        "\n",
        "    if len(pseudo_labels_df) > 0:\n",
        "        print(f\"\\n✅ PSEUDO-LABELING COMPLETE\")\n",
        "        print(f\"Generated {len(pseudo_labels_df)} high-quality labels for training\")\n",
        "        print(f\"Ready for HuggingFace model fine-tuning!\")\n",
        "\n",
        "        # Preview the training data\n",
        "        print(f\"\\nTraining Data Preview:\")\n",
        "        display_cols = ['text', 'pred_label', 'pred_category', 'confidence']\n",
        "        for idx, row in pseudo_labels_df.head(3).iterrows():\n",
        "            text_preview = row['text'][:60] + \"...\" if len(row['text']) > 60 else row['text']\n",
        "            print(f\"   {row['pred_label']} | {row['pred_category']} | {row['confidence']:.2f} | {text_preview}\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No pseudo-labels generated - will use pre-trained models only\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SKIPPING PSEUDO-LABELING (Gemini not available)\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Will proceed with pre-trained HuggingFace models only\")\n",
        "    pseudo_labels_df = pd.DataFrame()\n",
        "\n",
        "print(f\"\\nTraining data preparation: {'✅ Complete' if len(pseudo_labels_df) > 0 else '❌ Skipped'}\")\n",
        "print(f\"Ready for HuggingFace model training: {'✅ Yes' if len(pseudo_labels_df) > 0 else '⚠️ Pre-trained only'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f255cad8",
      "metadata": {
        "id": "f255cad8"
      },
      "source": [
        "## 7. HuggingFace Model Training with Pseudo-Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2235ac4d",
      "metadata": {
        "id": "2235ac4d",
        "outputId": "3d6e23a9-32cd-4fac-9c0e-aa8e458aa6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ransformers (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mHUGGINGFACE MODEL TRAINING WITH PSEUDO-LABELS (no sentiment, fused policy logic)\n",
            "============================================================\n",
            "Mode: pre-trained\n",
            "\n",
            "🔄 PRE-TRAINED MODE (no sentiment)\n",
            "\n",
            "============================================================\n",
            "TESTING MODELS\n",
            "============================================================\n",
            "Testing with: Sample data | n=5\n",
            "\n",
            "Running inference… (pre-trained)  samples=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Processing reviews: 100%|██████████| 5/5 [00:36<00:00,  7.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Inference saved → results/predictions/predictions_pre-trained.csv  rows=5\n",
            "\n",
            "📊 INFERENCE RESULTS\n",
            "==================================================\n",
            " id                                                  text pred_label pred_category confidence  model_type toxicity_label  toxicity_score\n",
            "  1 Use my promo code EAT10 for 10% off! DM me on What...     REJECT        No_Ads       None pre-trained          toxic          0.0439\n",
            "  2 Great laksa; broth was rich and staff friendly. Wi...    APPROVE          None       None pre-trained          toxic          0.0007\n",
            "  3 Crypto is the future. Buy BTC now! Nothing to do w...     REJECT    Irrelevant       None pre-trained          toxic          0.0158\n",
            "  4               Overpriced scammers. Society is doomed.     REJECT Rant_No_Visit       None pre-trained          toxic          0.1205\n",
            "  5 Visited on 18 Aug, ordered set A; cashier fixed a ...    APPROVE          None       None pre-trained          toxic          0.0008\n",
            "\n",
            "📈 RESULTS SUMMARY\n",
            "pred_label\n",
            "REJECT     3\n",
            "APPROVE    2\n",
            "Name: count, dtype: int64\n",
            "Average Confidence (fine-tuned only): nan\n",
            "\n",
            "✅ MODEL TRAINING AND TESTING COMPLETE\n",
            "Training Mode: PRE-TRAINED\n",
            "Ready for Model Persistence: ✅ Yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!pip uninstall -y transformers -q\n",
        "!pip install -qU \"transformers>=4.45.0\" \"accelerate>=0.34.0\" \"huggingface_hub>=0.23.0\"\n",
        "\n",
        "# 7. HuggingFace Model Training with Pseudo-Labels\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, DataCollatorWithPadding, pipeline as hf_pipeline,\n",
        "    __version__ as HF_VER,   # <-- for version-aware args\n",
        ")\n",
        "from packaging.version import parse                # <-- for version-aware args\n",
        "from datasets import Dataset\n",
        "import torch, numpy as np, pandas as pd, re, os\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"HUGGINGFACE MODEL TRAINING WITH PSEUDO-LABELS (no sentiment, fused policy logic)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ---- import your constants (as provided)\n",
        "from src.core.constants import (\n",
        "    DEFAULT_MODELS, ZERO_SHOT_LABELS, ZERO_SHOT_TO_POLICY,\n",
        "    POLICY_CATEGORIES, LABELS, CONFIDENCE_THRESHOLDS\n",
        ")\n",
        "\n",
        "# ---- device & training mode (same behavior)\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "has_training_data = ('pseudo_labels_df' in locals()) and (len(pseudo_labels_df) > 0)\n",
        "training_mode = \"fine-tuning\" if has_training_data else \"pre-trained\"\n",
        "print(\"Mode:\", training_mode)\n",
        "\n",
        "# ---- models (NO sentiment)\n",
        "BASE_MODEL      = \"distilbert-base-uncased\"\n",
        "TOXIC_MODEL     = DEFAULT_MODELS['TOXIC']\n",
        "ZERO_SHOT_MODEL = DEFAULT_MODELS['ZERO_SHOT']\n",
        "\n",
        "# ========= new policy helpers (ad evidence + toxicity gate) =========\n",
        "AD_PATTERNS = [\n",
        "    r\"https?://\", r\"\\bwww\\.\", r\"\\.[a-z]{2,6}\\b\",\n",
        "    r\"\\b(?:\\+?\\d[\\s\\-()]*){7,}\\b\",\n",
        "    r\"\\bpromo(?:\\s*code)?\\b\", r\"\\bdiscount\\b\", r\"\\bcoupon\\b\",\n",
        "    r\"\\breferral\\b\", r\"\\buse\\s*code\\b\", r\"\\benter\\s*code\\b\",\n",
        "    r\"\\bwhatsapp\\b\",\n",
        "    r\"\\bdm\\s+(?:me|us)\\b\",\n",
        "    r\"\\bcontact\\s+(?:us|me)\\b\", r\"\\bcall\\s+(?:us|me)\\b\",\n",
        "]\n",
        "AD_REGEX = re.compile(\"|\".join(AD_PATTERNS), flags=re.IGNORECASE)\n",
        "TOX_TO_RANT = {\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\"}\n",
        "TOX_TO_IRRELEVANT = {\"identity_hate\"}\n",
        "\n",
        "def ad_evidence(text: str):\n",
        "    t = text or \"\"\n",
        "    m = AD_REGEX.search(t)\n",
        "    return bool(m), (m.group(0) if m else \"\")\n",
        "\n",
        "def tox_top_label(tox_output):\n",
        "    \"\"\"\n",
        "    Normalize HF toxicity pipeline outputs into (label, score).\n",
        "    Handles dict, list[dict], list[list[dict]].\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if isinstance(tox_output, dict):\n",
        "            candidates = [tox_output]\n",
        "        elif isinstance(tox_output, list):\n",
        "            if len(tox_output) and isinstance(tox_output[0], dict):\n",
        "                candidates = tox_output\n",
        "            elif len(tox_output) and isinstance(tox_output[0], list):\n",
        "                candidates = tox_output[0]\n",
        "            else:\n",
        "                candidates = []\n",
        "        else:\n",
        "            candidates = []\n",
        "        if not candidates:\n",
        "            return \"NONE\", 0.0\n",
        "        best = max(candidates, key=lambda d: float(d.get(\"score\", 0.0)))\n",
        "        return best.get(\"label\", \"NONE\"), float(best.get(\"score\", 0.0))\n",
        "    except Exception:\n",
        "        return \"NONE\", 0.0\n",
        "\n",
        "\n",
        "def policy_zero_shot_fused(zshot, toxic, text: str,\n",
        "                           tau_irrelevant=0.55, tau_rant=0.55,\n",
        "                           tau_ads=0.70, tox_tau=0.50, ads_margin=0.10):\n",
        "    \"\"\"\n",
        "    1) Toxicity gate:\n",
        "         - identity_hate -> Irrelevant\n",
        "         - toxic/insult/obscene/threat -> Rant_No_Visit\n",
        "    2) Else if Irrelevant/Rant over thresholds -> that category\n",
        "    3) Else if Ads high + ad evidence + margin -> No_Ads\n",
        "    4) Else -> None\n",
        "    Returns: (pred_label 'APPROVE'/'REJECT', pred_category)\n",
        "    \"\"\"\n",
        "    # zero-shot on your label set\n",
        "    zs_res = zshot(text, candidate_labels=ZERO_SHOT_LABELS,\n",
        "                   hypothesis_template=\"This review is {}.\", multi_label=True)\n",
        "    zs = {lab: float(scr) for lab, scr in zip(zs_res[\"labels\"], zs_res[\"scores\"])}\n",
        "    ads  = zs.get(ZERO_SHOT_LABELS[0], 0.0)\n",
        "    irr  = zs.get(ZERO_SHOT_LABELS[1], 0.0)\n",
        "    rant = zs.get(ZERO_SHOT_LABELS[2], 0.0)\n",
        "    none = zs.get(ZERO_SHOT_LABELS[3], 0.0)\n",
        "\n",
        "    # toxicity top label\n",
        "    tox_label, tox_score = tox_top_label(toxic(text))\n",
        "\n",
        "\n",
        "    if tox_label and tox_score >= tox_tau:\n",
        "        if tox_label in TOX_TO_RANT:\n",
        "            return LABELS['REJECT'], POLICY_CATEGORIES['RANT_NO_VISIT']\n",
        "        if tox_label in TOX_TO_IRRELEVANT:\n",
        "            return LABELS['REJECT'], POLICY_CATEGORIES['IRRELEVANT']\n",
        "\n",
        "    if max(irr, rant) >= min(tau_irrelevant, tau_rant):\n",
        "        return LABELS['REJECT'], (POLICY_CATEGORIES['IRRELEVANT'] if irr >= rant else POLICY_CATEGORIES['RANT_NO_VISIT'])\n",
        "\n",
        "    has_ads, _ = ad_evidence(text)\n",
        "    if has_ads and (ads >= tau_ads) and (ads >= max(irr, rant) + ads_margin):\n",
        "        return LABELS['REJECT'], POLICY_CATEGORIES['NO_ADS']\n",
        "\n",
        "    return LABELS['APPROVE'], POLICY_CATEGORIES['NONE']\n",
        "\n",
        "# ========= metrics & training (binary, same as before) =========\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted', zero_division=0)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
        "\n",
        "def prepare_training_data(pseudo_df):\n",
        "    train_texts  = pseudo_df['text'].tolist()\n",
        "    train_labels = [1 if label == 'REJECT' else 0 for label in pseudo_df['pred_label']]\n",
        "    return train_texts, train_labels\n",
        "\n",
        "def train_custom_classification_model(train_texts, train_labels, model_name=\"review-policy-classifier\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=2)\n",
        "    enc = tokenizer(train_texts, truncation=True, padding=True, max_length=256, return_tensors=\"pt\")\n",
        "    train_ds = Dataset.from_dict({'input_ids': enc['input_ids'], 'attention_mask': enc['attention_mask'], 'labels': train_labels})\n",
        "\n",
        "    # ---- version-aware TrainingArguments (v4 vs v5)\n",
        "    common_kwargs = dict(\n",
        "        output_dir=f'./models/fine-tuned/{model_name}',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f'./logs/{model_name}',\n",
        "        logging_steps=10,\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        greater_is_better=True,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "    if parse(HF_VER).major >= 5:\n",
        "        common_kwargs[\"eval_strategy\"] = \"epoch\"\n",
        "    else:\n",
        "        common_kwargs[\"evaluation_strategy\"] = \"epoch\"\n",
        "\n",
        "    args = TrainingArguments(**common_kwargs)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model, args=args,\n",
        "        train_dataset=train_ds, eval_dataset=train_ds,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "    save_dir = f'./models/fine-tuned/{model_name}'\n",
        "    trainer.save_model(save_dir)\n",
        "    tokenizer.save_pretrained(save_dir)\n",
        "    print(f\"✅ Model saved to: {save_dir}\")\n",
        "    return model, tokenizer, save_dir\n",
        "\n",
        "def load_aux_pipelines(device=None):\n",
        "    toxic = hf_pipeline(\"text-classification\", model=TOXIC_MODEL, top_k=None, device=device)\n",
        "    zshot = hf_pipeline(\"zero-shot-classification\", model=ZERO_SHOT_MODEL, device=device)\n",
        "    return toxic, zshot\n",
        "\n",
        "def predict_with_custom_model(text, model, tokenizer):\n",
        "    inputs = tokenizer(text, truncation=True, padding=True, max_length=256, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        conf = float(probs.max())\n",
        "        pred = int(probs.argmax())\n",
        "    return (\"REJECT\" if pred == 1 else \"APPROVE\"), conf\n",
        "\n",
        "def run_inference_pipeline(df, tau=CONFIDENCE_THRESHOLDS['DEFAULT']):\n",
        "    print(f\"\\nRunning inference… ({training_mode})  samples={len(df)}\")\n",
        "    toxic_pipeline, zshot_pipeline = load_aux_pipelines(device)\n",
        "    results = []\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing reviews\"):\n",
        "        txt = str(row['text'])\n",
        "\n",
        "        # ---- robust access to optional custom model\n",
        "        cc = TRAINED_MODELS.get('custom_classifier')\n",
        "        if cc is not None:\n",
        "            pred_label, confidence = predict_with_custom_model(txt, cc['model'], cc['tokenizer'])\n",
        "            pred_category = \"Custom_Trained\"\n",
        "        else:\n",
        "            pred_label, pred_category = policy_zero_shot_fused(\n",
        "                zshot=zshot_pipeline, toxic=toxic_pipeline, text=txt,\n",
        "                tau_irrelevant=0.55, tau_rant=0.55, tau_ads=0.70, tox_tau=0.50, ads_margin=0.10\n",
        "            )\n",
        "            confidence = None  # rule-based fusion\n",
        "\n",
        "        # Optional: record toxicity top label/score for debugging\n",
        "        try:\n",
        "            tox_label, tox_score = tox_top_label(toxic_pipeline(txt))\n",
        "        except Exception:\n",
        "            tox_label, tox_score = \"NONE\", 0.0\n",
        "\n",
        "        results.append({\n",
        "            \"id\": row.get('id', len(results)+1),\n",
        "            \"text\": txt,\n",
        "            \"pred_label\": pred_label,\n",
        "            \"pred_category\": pred_category,\n",
        "            \"confidence\": (round(float(confidence), 4) if confidence is not None else None),\n",
        "            \"toxicity_label\": tox_label,\n",
        "            \"toxicity_score\": round(float(tox_score), 4),\n",
        "            \"model_type\": training_mode\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    os.makedirs(\"results/predictions\", exist_ok=True)\n",
        "    out_path = f'results/predictions/predictions_{training_mode}.csv'\n",
        "    results_df.to_csv(out_path, index=False)\n",
        "    print(f\"✅ Inference saved → {out_path}  rows={len(results_df)}\")\n",
        "    return results_df\n",
        "\n",
        "# ========= Train (if pseudo-labels) or use pre-trained =========\n",
        "TRAINED_MODELS = {\"custom_classifier\": None}   # <-- init key to avoid KeyError\n",
        "if training_mode == \"fine-tuning\":\n",
        "    print(\"\\n🎯 FINE-TUNING MODE\")\n",
        "    tr_texts, tr_labels = prepare_training_data(pseudo_labels_df)\n",
        "    model, tok, model_path = train_custom_classification_model(tr_texts, tr_labels, \"review-policy-classifier\")\n",
        "    TRAINED_MODELS['custom_classifier'] = {'model_path': model_path, 'model': model, 'tokenizer': tok}\n",
        "else:\n",
        "    print(\"\\n🔄 PRE-TRAINED MODE (no sentiment)\")\n",
        "    TRAINED_MODELS['custom_classifier'] = None\n",
        "\n",
        "# ========= Test on available data (same style) =========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if 'df' in locals() and len(df) > 0:\n",
        "    test_data = df\n",
        "    src = \"Sample data\"\n",
        "elif 'pseudo_labels_df' in locals() and len(pseudo_labels_df) > 0:\n",
        "    test_data = pseudo_labels_df[['id','text']].head(5)\n",
        "    src = \"Pseudo-labeled data\"\n",
        "else:\n",
        "    test_data = pd.DataFrame({'id':[1,2], 'text':[\n",
        "        \"Great food and service!\",\n",
        "        \"Use my promo code SAVE20 for discounts!\"\n",
        "    ]})\n",
        "    src = \"Minimal test data\"\n",
        "\n",
        "print(f\"Testing with: {src} | n={len(test_data)}\")\n",
        "hf_results = run_inference_pipeline(test_data, tau=CONFIDENCE_THRESHOLDS['DEFAULT'])\n",
        "\n",
        "# Pretty print head\n",
        "print(\"\\n📊 INFERENCE RESULTS\")\n",
        "print(\"=\"*50)\n",
        "disp_cols = ['id','text','pred_label','pred_category','confidence','model_type','toxicity_label','toxicity_score']\n",
        "dd = hf_results.copy()\n",
        "dd['text'] = dd['text'].apply(lambda x: x[:50]+\"...\" if isinstance(x,str) and len(x)>50 else x)\n",
        "print(dd[disp_cols].head(10).to_string(index=False))\n",
        "\n",
        "# Summary\n",
        "print(\"\\n📈 RESULTS SUMMARY\")\n",
        "print(hf_results['pred_label'].value_counts())\n",
        "print(f\"Average Confidence (fine-tuned only): {hf_results['confidence'].dropna().mean() if 'confidence' in hf_results else float('nan'):.3f}\")\n",
        "\n",
        "print(\"\\n✅ MODEL TRAINING AND TESTING COMPLETE\")\n",
        "print(f\"Training Mode: {training_mode.upper()}\")\n",
        "print(\"Ready for Model Persistence: ✅ Yes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c020a20",
      "metadata": {
        "id": "4c020a20"
      },
      "source": [
        "## 9. Model Persistence and Export (After Training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54193be4",
      "metadata": {
        "id": "54193be4",
        "outputId": "ba60baec-20db-4985-bbc2-597f9b319ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL PERSISTENCE AND DATA EXPORT\n",
            "============================================================\n",
            "Training Mode: pre-trained\n",
            "Timestamp: 20250830_093732\n",
            "\n",
            "📦 SAVING PRE-TRAINED MODEL REFERENCES\n",
            "\n",
            "⚠️ No training data to save\n",
            "\n",
            "💾 SAVING PREDICTION RESULTS\n",
            "✅ Predictions saved: data/predictions/predictions_20250830_093732.csv\n",
            "   Prediction Labels: {'REJECT': 3, 'APPROVE': 2}\n",
            "   Average Confidence: nan\n",
            "✅ Model info saved: results/model_info/model_info_20250830_093732.json\n",
            "\n",
            "🚀 CREATING DEPLOYMENT STRUCTURE\n",
            "✅ Sample data for inference: data/actual/sample_reviews.csv\n",
            "✅ Latest model config: models/saved_models/latest_config.json\n",
            "✅ Model loader utilities: src/utils/model_loader.py\n",
            "\n",
            "============================================================\n",
            "PERSISTENCE COMPLETE\n",
            "============================================================\n",
            "✅ Training Mode: pre-trained\n",
            "✅ Timestamp: 20250830_093732\n",
            "⚠️ Custom Model: None (using pre-trained)\n",
            "✅ Model Info: results/model_info/model_info_20250830_093732.json\n",
            "✅ Latest Config: models/saved_models/latest_config.json\n",
            "✅ Predictions: data/predictions/predictions_20250830_093732.csv\n",
            "   Processed: 5 reviews\n",
            "\n",
            "🎯 READY FOR INFERENCE PIPELINE\n",
            "   Use: models/saved_models/latest_config.json\n",
            "   Data: data/actual/sample_reviews.csv\n",
            "   Load: src/utils/model_loader.py\n",
            "\n",
            "✅ MODEL TRAINING AND PERSISTENCE COMPLETE!\n"
          ]
        }
      ],
      "source": [
        "# Model Persistence and Training Data Export\n",
        "import os\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"MODEL PERSISTENCE AND DATA EXPORT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs('models/saved_models', exist_ok=True)\n",
        "os.makedirs('data/training', exist_ok=True)\n",
        "os.makedirs('data/predictions', exist_ok=True)\n",
        "os.makedirs('results/model_info', exist_ok=True)\n",
        "\n",
        "# Generate timestamp for versioning\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Model information\n",
        "model_info = {\n",
        "    \"training_timestamp\": timestamp,\n",
        "    \"training_mode\": training_mode,\n",
        "    \"base_model\": BASE_MODEL if training_mode == \"fine-tuning\" else \"pre-trained-only\",\n",
        "    \"auxiliary_models\": {\n",
        "      \"toxicity_model\": TOXIC_MODEL,\n",
        "      \"zero_shot_model\": ZERO_SHOT_MODEL\n",
        "  },\n",
        "    \"training_data_size\": len(pseudo_labels_df) if has_training_data else 0,\n",
        "    \"confidence_threshold\": CONFIDENCE_THRESHOLDS['DEFAULT'],\n",
        "    \"performance_metrics\": {}\n",
        "}\n",
        "\n",
        "print(f\"Training Mode: {training_mode}\")\n",
        "print(f\"Timestamp: {timestamp}\")\n",
        "\n",
        "# Save trained models\n",
        "if training_mode == \"fine-tuning\" and TRAINED_MODELS['custom_classifier'] is not None:\n",
        "    print(f\"\\n💾 SAVING FINE-TUNED MODELS\")\n",
        "\n",
        "    # Custom model is already saved during training\n",
        "    custom_model_path = TRAINED_MODELS['custom_classifier']['model_path']\n",
        "    final_model_path = f'models/saved_models/review_classifier_{timestamp}'\n",
        "\n",
        "    # Copy to final location with timestamp\n",
        "    if os.path.exists(custom_model_path):\n",
        "        shutil.copytree(custom_model_path, final_model_path, dirs_exist_ok=True)\n",
        "        print(f\"✅ Fine-tuned model copied to: {final_model_path}\")\n",
        "\n",
        "        model_info[\"custom_model_path\"] = final_model_path\n",
        "        model_info[\"model_files\"] = {\n",
        "            \"config\": f\"{final_model_path}/config.json\",\n",
        "            \"model\": f\"{final_model_path}/pytorch_model.bin\",\n",
        "            \"tokenizer\": f\"{final_model_path}/tokenizer.json\"\n",
        "        }\n",
        "\n",
        "        # Test model loading\n",
        "        try:\n",
        "            from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "            test_tokenizer = AutoTokenizer.from_pretrained(final_model_path)\n",
        "            test_model = AutoModelForSequenceClassification.from_pretrained(final_model_path)\n",
        "            print(\"✅ Model loading test successful\")\n",
        "            model_info[\"model_loadable\"] = True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Model loading test failed: {e}\")\n",
        "            model_info[\"model_loadable\"] = False\n",
        "    else:\n",
        "        print(f\"❌ Custom model path not found: {custom_model_path}\")\n",
        "        model_info[\"custom_model_path\"] = None\n",
        "\n",
        "else:\n",
        "    print(f\"\\n📦 SAVING PRE-TRAINED MODEL REFERENCES\")\n",
        "    model_info[\"custom_model_path\"] = None\n",
        "    model_info[\"model_files\"] = None\n",
        "\n",
        "# Save auxiliary model pipeline state (for consistency in inference)\n",
        "auxiliary_info = {\n",
        "    \"toxicity_model\": TOXIC_MODEL,\n",
        "    \"zero_shot_model\": ZERO_SHOT_MODEL,\n",
        "    \"device_used\": 0 if torch.cuda.is_available() else -1,\n",
        "    \"models_loaded\": False  # we store names; loader will instantiate\n",
        "}\n",
        "\n",
        "\n",
        "# Save training data if available\n",
        "if has_training_data:\n",
        "    print(f\"\\n💾 SAVING TRAINING DATA\")\n",
        "\n",
        "    # Save pseudo-labeled training data\n",
        "    training_data_path = f'data/training/pseudo_labels_{timestamp}.csv'\n",
        "    pseudo_labels_df.to_csv(training_data_path, index=False)\n",
        "    print(f\"✅ Training data saved: {training_data_path}\")\n",
        "\n",
        "    model_info[\"training_data_path\"] = training_data_path\n",
        "    model_info[\"training_data_size\"] = len(pseudo_labels_df)\n",
        "\n",
        "    # Save label distribution\n",
        "    label_dist = pseudo_labels_df['pred_label'].value_counts().to_dict()\n",
        "    model_info[\"training_label_distribution\"] = label_dist\n",
        "    print(f\"   Training Labels: {label_dist}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n⚠️ No training data to save\")\n",
        "    model_info[\"training_data_path\"] = None\n",
        "\n",
        "# Save prediction results\n",
        "if 'hf_results' in locals():\n",
        "    print(f\"\\n💾 SAVING PREDICTION RESULTS\")\n",
        "\n",
        "    predictions_path = f'data/predictions/predictions_{timestamp}.csv'\n",
        "    hf_results.to_csv(predictions_path, index=False)\n",
        "    print(f\"✅ Predictions saved: {predictions_path}\")\n",
        "\n",
        "    model_info[\"predictions_path\"] = predictions_path\n",
        "    model_info[\"predictions_count\"] = len(hf_results)\n",
        "\n",
        "    # Add performance metrics\n",
        "    pred_dist = hf_results['pred_label'].value_counts().to_dict()\n",
        "    avg_confidence = hf_results['confidence'].mean()\n",
        "\n",
        "    model_info[\"performance_metrics\"] = {\n",
        "        \"prediction_distribution\": pred_dist,\n",
        "        \"average_confidence\": round(float(avg_confidence), 4),\n",
        "        \"total_processed\": len(hf_results)\n",
        "    }\n",
        "    print(f\"   Prediction Labels: {pred_dist}\")\n",
        "    print(f\"   Average Confidence: {avg_confidence:.4f}\")\n",
        "\n",
        "# Save comprehensive model information\n",
        "model_info_path = f'results/model_info/model_info_{timestamp}.json'\n",
        "with open(model_info_path, 'w') as f:\n",
        "    json.dump(model_info, f, indent=2, default=str)\n",
        "\n",
        "print(f\"✅ Model info saved: {model_info_path}\")\n",
        "\n",
        "# Create deployment-ready structure for inference pipeline\n",
        "print(f\"\\n🚀 CREATING DEPLOYMENT STRUCTURE\")\n",
        "\n",
        "# Create data/actual with sample data for inference pipeline\n",
        "os.makedirs('data/actual', exist_ok=True)\n",
        "\n",
        "# If we have results, save a sample to data/actual for the inference pipeline\n",
        "if 'hf_results' in locals() and len(hf_results) > 0:\n",
        "    # Create sample data for inference testing\n",
        "    sample_actual = hf_results[['id', 'text']].head(3).copy()\n",
        "    sample_actual.to_csv('data/actual/sample_reviews.csv', index=False)\n",
        "    print(\"✅ Sample data for inference: data/actual/sample_reviews.csv\")\n",
        "\n",
        "# Save latest model paths for inference pipeline\n",
        "latest_model_config = {\n",
        "    \"latest_model_info\": model_info_path,\n",
        "    \"training_mode\": training_mode,\n",
        "    \"custom_model_path\": model_info.get(\"custom_model_path\"),\n",
        "    \"auxiliary_models\": auxiliary_info,\n",
        "    \"confidence_threshold\": CONFIDENCE_THRESHOLDS['DEFAULT'],\n",
        "    \"timestamp\": timestamp\n",
        "}\n",
        "\n",
        "with open('models/saved_models/latest_config.json', 'w') as f:\n",
        "    json.dump(latest_model_config, f, indent=2)\n",
        "\n",
        "print(\"✅ Latest model config: models/saved_models/latest_config.json\")\n",
        "\n",
        "# Create model loading utilities for inference\n",
        "model_loader_code = '''\"\"\"\n",
        "Model Loading Utilities for Review Classification Pipeline\n",
        "Generated automatically during training\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import torch\n",
        "\n",
        "def load_latest_models():\n",
        "    \"\"\"Load the most recently trained models\"\"\"\n",
        "\n",
        "    config_path = 'models/saved_models/latest_config.json'\n",
        "\n",
        "    if not os.path.exists(config_path):\n",
        "        raise FileNotFoundError(\"No trained models found. Run training pipeline first.\")\n",
        "\n",
        "    with open(config_path) as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    models = {}\n",
        "\n",
        "    # Load custom model if available\n",
        "    if config['custom_model_path'] and os.path.exists(config['custom_model_path']):\n",
        "        models['custom'] = {\n",
        "            'tokenizer': AutoTokenizer.from_pretrained(config['custom_model_path']),\n",
        "            'model': AutoModelForSequenceClassification.from_pretrained(config['custom_model_path'])\n",
        "        }\n",
        "\n",
        "    # Load auxiliary models\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    aux_config = config['auxiliary_models']\n",
        "\n",
        "    models['auxiliary'] = {\n",
        "    'toxicity': pipeline(\"text-classification\",\n",
        "                         model=aux_config['toxicity_model'], device=device),\n",
        "    'zero_shot': pipeline(\"zero-shot-classification\",\n",
        "                          model=aux_config['zero_shot_model'], device=device),\n",
        "}\n",
        "\n",
        "\n",
        "    return models, config\n",
        "\n",
        "def predict_review(text, models, config):\n",
        "    \"\"\"Make prediction using loaded models\"\"\"\n",
        "\n",
        "    if 'custom' in models:\n",
        "        # Use fine-tuned model\n",
        "        inputs = models['custom']['tokenizer'](\n",
        "            text, truncation=True, padding=True,\n",
        "            max_length=256, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = models['custom']['model'](**inputs)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            confidence = float(torch.max(predictions))\n",
        "            predicted_class = int(torch.argmax(predictions))\n",
        "\n",
        "        label = \"REJECT\" if predicted_class == 1 else \"APPROVE\"\n",
        "\n",
        "    else:\n",
        "        # Use zero-shot classification\n",
        "        # Implementation would mirror the training notebook logic\n",
        "        label = \"APPROVE\"  # Placeholder\n",
        "        confidence = 0.5\n",
        "\n",
        "    return {\n",
        "        'label': label,\n",
        "        'confidence': confidence,\n",
        "        'model_type': config['training_mode']\n",
        "    }\n",
        "'''\n",
        "\n",
        "Path(\"src/utils\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"src/__init__.py\").touch(exist_ok=True)\n",
        "Path(\"src/utils/__init__.py\").touch(exist_ok=True)\n",
        "\n",
        "with open('src/utils/model_loader.py', 'w') as f:\n",
        "    f.write(model_loader_code)\n",
        "\n",
        "print(\"✅ Model loader utilities: src/utils/model_loader.py\")\n",
        "\n",
        "# Summary\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"PERSISTENCE COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"✅ Training Mode: {training_mode}\")\n",
        "print(f\"✅ Timestamp: {timestamp}\")\n",
        "\n",
        "if model_info.get(\"custom_model_path\"):\n",
        "    print(f\"✅ Custom Model: {model_info['custom_model_path']}\")\n",
        "else:\n",
        "    print(f\"⚠️ Custom Model: None (using pre-trained)\")\n",
        "\n",
        "print(f\"✅ Model Info: {model_info_path}\")\n",
        "print(f\"✅ Latest Config: models/saved_models/latest_config.json\")\n",
        "\n",
        "if has_training_data:\n",
        "    print(f\"✅ Training Data: {model_info['training_data_path']}\")\n",
        "    print(f\"   Size: {model_info['training_data_size']} examples\")\n",
        "\n",
        "if 'hf_results' in locals():\n",
        "    print(f\"✅ Predictions: {model_info['predictions_path']}\")\n",
        "    print(f\"   Processed: {model_info['predictions_count']} reviews\")\n",
        "\n",
        "print(f\"\\n🎯 READY FOR INFERENCE PIPELINE\")\n",
        "print(f\"   Use: models/saved_models/latest_config.json\")\n",
        "print(f\"   Data: data/actual/sample_reviews.csv\")\n",
        "print(f\"   Load: src/utils/model_loader.py\")\n",
        "\n",
        "print(f\"\\n✅ MODEL TRAINING AND PERSISTENCE COMPLETE!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "981d961c",
      "metadata": {
        "id": "981d961c"
      },
      "source": [
        "## 10. Model Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e21722",
      "metadata": {
        "id": "e7e21722",
        "outputId": "36cab1ba-1d53-4a27-f23b-620ff804c548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for available prediction data...\n",
            "   Found prediction data: hf_results (5 rows)\n",
            "   Found prediction data: predictions_df (5 rows)\n",
            "   Found prediction data: df (5 rows)\n",
            "\n",
            "Using prediction data from: hf_results\n",
            "Columns available: ['id', 'text', 'pred_label', 'pred_category', 'confidence', 'toxicity_label', 'toxicity_score', 'model_type']\n",
            "\n",
            "Running comprehensive model evaluation...\n",
            "Model Performance Evaluation\n",
            "==================================================\n",
            "Total predictions analyzed: 5\n",
            "Using columns: pred_label, pred_category, confidence\n",
            "\n",
            "Label Distribution:\n",
            "   REJECT: 3 (60.0%)\n",
            "   APPROVE: 2 (40.0%)\n",
            "\n",
            "Policy Category Distribution:\n",
            "   None: 2 (40.0%)\n",
            "   No_Ads: 1 (20.0%)\n",
            "   Irrelevant: 1 (20.0%)\n",
            "   Rant_No_Visit: 1 (20.0%)\n",
            "\n",
            "Confidence Score Statistics:\n",
            "   (no numeric confidence values present — likely pre-trained/fusion mode)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Quality Assessment:\n",
            "   Average confidence: nan (⏸️ N/A)\n",
            "   High confidence rate: 0.0% (⏸️ N/A)\n",
            "\n",
            "Model Readiness for Production:\n",
            "   ✅ Sufficient predictions (5)\n",
            "   ⏸️ N/A (no numeric confidence)\n",
            "   ⏸️ N/A (no numeric confidence)\n",
            "   ✅ Good category coverage (4 categories)\n",
            "   ✅ Acceptable label balance (0.667)\n",
            "\n",
            "Overall Readiness: 3/5 (60%) - ⚠️ Needs Minor Improvements\n",
            "\n",
            "Evaluation results saved to: results/predictions/model_evaluation.json\n",
            "\n",
            "Evaluation Complete!\n",
            "   Model performance: ✅ Satisfactory\n",
            "   Ready for deployment: ❌ No\n",
            "   Integration ready: ✅ Yes (structured output format)\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation and Performance Analysis (Production-Quality)\n",
        "import os, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def evaluate_model_performance(predictions_df, output_dir='results/predictions'):\n",
        "    \"\"\"Comprehensive model evaluation matching production standards (robust to missing numeric confidence).\"\"\"\n",
        "\n",
        "    print(f\"Model Performance Evaluation\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    total_predictions = len(predictions_df)\n",
        "    print(f\"Total predictions analyzed: {total_predictions}\")\n",
        "\n",
        "    # auto-detect columns\n",
        "    label_col = category_col = confidence_col = None\n",
        "    for col in predictions_df.columns:\n",
        "        c = col.lower()\n",
        "        if ('label' in c or 'pred_label' in c) and label_col is None:\n",
        "            label_col = col\n",
        "        if 'category' in c and category_col is None:\n",
        "            category_col = col\n",
        "        if 'confidence' in c and confidence_col is None:\n",
        "            confidence_col = col\n",
        "\n",
        "    if not all([label_col, category_col, confidence_col]):\n",
        "        print(f\"❌ Missing required columns. Available columns: {list(predictions_df.columns)}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Using columns: {label_col}, {category_col}, {confidence_col}\")\n",
        "\n",
        "    # distributions\n",
        "    label_dist = predictions_df[label_col].value_counts()\n",
        "    print(f\"\\nLabel Distribution:\")\n",
        "    for label, count in label_dist.items():\n",
        "        print(f\"   {label}: {count} ({(count/total_predictions)*100:.1f}%)\")\n",
        "\n",
        "    category_dist = predictions_df[category_col].value_counts()\n",
        "    print(f\"\\nPolicy Category Distribution:\")\n",
        "    for cat, count in category_dist.items():\n",
        "        print(f\"   {cat}: {count} ({(count/total_predictions)*100:.1f}%)\")\n",
        "\n",
        "    # --- confidence handling (robust) ---\n",
        "    conf_series = pd.to_numeric(predictions_df[confidence_col], errors='coerce')  # non-numeric -> NaN\n",
        "    has_numeric_conf = conf_series.notna().any()\n",
        "\n",
        "    high_conf_threshold = 0.8\n",
        "    if has_numeric_conf:\n",
        "        stats = conf_series.describe()\n",
        "        print(f\"\\nConfidence Score Statistics:\")\n",
        "        print(f\"   Mean:   {stats['mean']:.3f}\")\n",
        "        print(f\"   Median: {stats['50%']:.3f}\")\n",
        "        print(f\"   Std:    {stats['std']:.3f}\")\n",
        "        print(f\"   Min:    {stats['min']:.3f}\")\n",
        "        print(f\"   Max:    {stats['max']:.3f}\")\n",
        "\n",
        "        high_conf_mask = conf_series >= high_conf_threshold\n",
        "        high_conf_percentage = (high_conf_mask.sum() / total_predictions) * 100\n",
        "\n",
        "        print(f\"\\nHigh Confidence Analysis (>= {high_conf_threshold}):\")\n",
        "        print(f\"   High confidence predictions: {int(high_conf_mask.sum())} ({high_conf_percentage:.1f}%)\")\n",
        "        if high_conf_mask.any():\n",
        "            for label, count in predictions_df.loc[high_conf_mask, label_col].value_counts().items():\n",
        "                print(f\"      {label}: {count}\")\n",
        "    else:\n",
        "        print(\"\\nConfidence Score Statistics:\")\n",
        "        print(\"   (no numeric confidence values present — likely pre-trained/fusion mode)\")\n",
        "        high_conf_percentage = 0.0  # nothing to report\n",
        "\n",
        "    # ---- plots ----\n",
        "    if has_numeric_conf:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    else:\n",
        "        # only top row plots if we lack numeric confidence\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        axes = np.atleast_2d(axes)  # make indexing consistent\n",
        "\n",
        "    # labels pie\n",
        "    axes[0, 0].pie(label_dist.values, labels=label_dist.index, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0, 0].set_title('Label Distribution')\n",
        "\n",
        "    # category bar\n",
        "    category_dist.plot(kind='bar', ax=axes[0, 1])\n",
        "    axes[0, 1].set_title('Policy Category Distribution')\n",
        "    axes[0, 1].set_xlabel('Category')\n",
        "    axes[0, 1].set_ylabel('Count')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    if has_numeric_conf:\n",
        "        # histogram\n",
        "        axes[1, 0].hist(conf_series.dropna(), bins=20, alpha=0.7)\n",
        "        axes[1, 0].axvline(x=high_conf_threshold, linestyle='--', label=f'High Conf Threshold ({high_conf_threshold})')\n",
        "        axes[1, 0].set_title('Confidence Score Distribution')\n",
        "        axes[1, 0].set_xlabel('Confidence Score')\n",
        "        axes[1, 0].set_ylabel('Frequency')\n",
        "        axes[1, 0].legend()\n",
        "\n",
        "        # box by label\n",
        "        tmp = pd.DataFrame({label_col: predictions_df[label_col], 'conf': conf_series})\n",
        "        sns.boxplot(data=tmp, x=label_col, y='conf', ax=axes[1, 1])\n",
        "        axes[1, 1].set_title('Confidence by Label')\n",
        "        axes[1, 1].set_xlabel('Label')\n",
        "        axes[1, 1].set_ylabel('Confidence Score')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ---- quality / readiness ----\n",
        "    print(f\"\\nQuality Assessment:\")\n",
        "    label_balance = (min(label_dist.values) / max(label_dist.values)) if len(label_dist) > 1 else 0.0\n",
        "    avg_confidence = float(conf_series.mean()) if has_numeric_conf else float('nan')\n",
        "\n",
        "    conf_status = (\"✅ High\" if has_numeric_conf and avg_confidence > 0.7\n",
        "                   else \"❌ Low\" if has_numeric_conf and avg_confidence < 0.5\n",
        "                   else \"⏸️ N/A\")\n",
        "    print(f\"   Average confidence: {avg_confidence:.3f} ({conf_status})\")\n",
        "\n",
        "    high_conf_rate = high_conf_percentage / 100 if has_numeric_conf else 0.0\n",
        "    hc_status = (\"✅ Good\" if has_numeric_conf and high_conf_rate > 0.5\n",
        "                 else \"❌ Low\" if has_numeric_conf and high_conf_rate < 0.2\n",
        "                 else \"⏸️ N/A\")\n",
        "    print(f\"   High confidence rate: {high_conf_percentage:.1f}% ({hc_status})\")\n",
        "\n",
        "    print(f\"\\nModel Readiness for Production:\")\n",
        "    readiness_score = 0; max_score = 5\n",
        "\n",
        "    if total_predictions >= 5:\n",
        "        readiness_score += 1; print(f\"   ✅ Sufficient predictions ({total_predictions})\")\n",
        "    else:\n",
        "        print(f\"   ❌ Insufficient predictions ({total_predictions})\")\n",
        "\n",
        "    if has_numeric_conf and avg_confidence >= 0.6:\n",
        "        readiness_score += 1; print(f\"   ✅ Reasonable average confidence ({avg_confidence:.3f})\")\n",
        "    else:\n",
        "        print(f\"   {'⏸️ N/A (no numeric confidence)' if not has_numeric_conf else f'❌ Low average confidence ({avg_confidence:.3f})'}\")\n",
        "\n",
        "    if has_numeric_conf and high_conf_percentage >= 30:\n",
        "        readiness_score += 1; print(f\"   ✅ Good high-confidence rate ({high_conf_percentage:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"   {'⏸️ N/A (no numeric confidence)' if not has_numeric_conf else f'❌ Low high-confidence rate ({high_conf_percentage:.1f}%)'}\")\n",
        "\n",
        "    if len(category_dist) >= 2:\n",
        "        readiness_score += 1; print(f\"   ✅ Good category coverage ({len(category_dist)} categories)\")\n",
        "    else:\n",
        "        print(f\"   ❌ Limited category coverage ({len(category_dist)} categories)\")\n",
        "\n",
        "    if label_balance >= 0.1:\n",
        "        readiness_score += 1; print(f\"   ✅ Acceptable label balance ({label_balance:.3f})\")\n",
        "    else:\n",
        "        print(f\"   ❌ Extreme label imbalance ({label_balance:.3f})\")\n",
        "\n",
        "    readiness_percentage = (readiness_score / max_score) * 100\n",
        "    readiness_status = (\"✅ Ready for Production\" if readiness_percentage >= 80\n",
        "                        else \"⚠️ Needs Minor Improvements\" if readiness_percentage >= 60\n",
        "                        else \"❌ Needs Major Improvements\")\n",
        "    print(f\"\\nOverall Readiness: {readiness_score}/{max_score} ({readiness_percentage:.0f}%) - {readiness_status}\")\n",
        "\n",
        "    evaluation_summary = {\n",
        "        'total_predictions': total_predictions,\n",
        "        'label_distribution': label_dist.to_dict(),\n",
        "        'category_distribution': category_dist.to_dict(),\n",
        "        'average_confidence': (None if not has_numeric_conf else float(avg_confidence)),\n",
        "        'high_confidence_rate': (None if not has_numeric_conf else float(high_conf_percentage)),\n",
        "        'readiness_score': readiness_score,\n",
        "        'readiness_percentage': readiness_percentage,\n",
        "        'readiness_status': readiness_status\n",
        "    }\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    evaluation_path = os.path.join(output_dir, 'model_evaluation.json')\n",
        "    with open(evaluation_path, 'w') as f:\n",
        "        json.dump(evaluation_summary, f, indent=2, default=str)\n",
        "    print(f\"\\nEvaluation results saved to: {evaluation_path}\")\n",
        "\n",
        "    return evaluation_summary\n",
        "\n",
        "# Check for available prediction data and run evaluation\n",
        "print(\"Checking for available prediction data...\")\n",
        "\n",
        "# Look for different possible variable names\n",
        "prediction_vars = []\n",
        "available_vars = dir()\n",
        "\n",
        "# Check for common prediction variable names\n",
        "possible_names = ['hf_results', 'all_predictions_df', 'predictions_df', 'results_df', 'df']\n",
        "for var_name in possible_names:\n",
        "    if var_name in available_vars:\n",
        "        var_value = globals()[var_name]\n",
        "        if hasattr(var_value, 'shape') and len(var_value) > 0:\n",
        "            # Check if it looks like prediction data\n",
        "            columns = list(var_value.columns) if hasattr(var_value, 'columns') else []\n",
        "            if any('label' in col.lower() or 'pred' in col.lower() for col in columns):\n",
        "                prediction_vars.append((var_name, var_value))\n",
        "                print(f\"   Found prediction data: {var_name} ({len(var_value)} rows)\")\n",
        "\n",
        "if prediction_vars:\n",
        "    # Use the most likely prediction dataset\n",
        "    var_name, predictions_df = prediction_vars[0]\n",
        "    print(f\"\\nUsing prediction data from: {var_name}\")\n",
        "    print(f\"Columns available: {list(predictions_df.columns)}\")\n",
        "\n",
        "    # Run comprehensive evaluation\n",
        "    print(f\"\\nRunning comprehensive model evaluation...\")\n",
        "    evaluation_results = evaluate_model_performance(predictions_df)\n",
        "\n",
        "    if evaluation_results:\n",
        "        print(f\"\\nEvaluation Complete!\")\n",
        "        print(f\"   Model performance: {'✅ Satisfactory' if evaluation_results['readiness_percentage'] >= 60 else '❌ Needs improvement'}\")\n",
        "        print(f\"   Ready for deployment: {'✅ Yes' if evaluation_results['readiness_percentage'] >= 80 else '❌ No'}\")\n",
        "        print(f\"   Integration ready: ✅ Yes (structured output format)\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No prediction data available for evaluation\")\n",
        "    print(\"Available variables:\", [var for var in available_vars if not var.startswith('_')])\n",
        "    print(\"\\nTo fix this issue:\")\n",
        "    print(\"1. Run the HuggingFace Pipeline cell (cell 7) first\")\n",
        "    print(\"2. Make sure the pipeline completes successfully\")\n",
        "    print(\"3. Then run this evaluation cell\")\n",
        "    print(\"\\nThe HuggingFace pipeline should create a 'hf_results' variable with predictions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598ac73c",
      "metadata": {
        "id": "598ac73c"
      },
      "source": [
        "## 11. Pipeline Summary and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5638aff5",
      "metadata": {
        "id": "5638aff5",
        "outputId": "e4acf669-150a-4e68-a4c0-b0ce4ee5e10a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REVIEW-RATER PIPELINE ARCHITECTURE 2.0\n",
            "======================================================================\n",
            "\n",
            "1. ENVIRONMENT SETUP\n",
            "   Platform: Google Colab\n",
            "   GPU Available: ❌ No\n",
            "   Device: -1\n",
            "\n",
            "2. DIRECTORY STRUCTURE\n",
            "   ✅ data/raw\n",
            "   ✅ data/clean\n",
            "   ✅ data/pseudo-label\n",
            "   ✅ data/training\n",
            "   ✅ data/testing\n",
            "   ✅ data/actual\n",
            "   ✅ data/sample\n",
            "   ✅ models/saved_models\n",
            "   ✅ models/cache\n",
            "   ✅ results/predictions\n",
            "   ❌ results/inference\n",
            "\n",
            "3. PIPELINE ARCHITECTURE\n",
            "   Training Flow (00_ipynb):\n",
            "      data/raw → (external) → data/clean\n",
            "      data/clean → (gemini) → data/pseudo-label\n",
            "      data/pseudo-label → data/testing + data/training\n",
            "      data/clean → data/training (combined)\n",
            "      HuggingFace training on data/training with feedback loop\n",
            "      Trained models → models/saved_models\n",
            "\n",
            "   Inference Flow (01_ipynb):\n",
            "      data/actual → models/saved_models → inference → results/inference\n",
            "\n",
            "4. COMPONENT STATUS\n",
            "   ✅ Constants loaded\n",
            "   ✅ Sample data ready\n",
            "   ✅ HuggingFace ready\n",
            "   ✅ Gemini available\n",
            "   ✅ Directory structure\n",
            "\n",
            "5. MODEL PERFORMANCE\n",
            "   ✅ Predictions available: 5 reviews\n",
            "   ✅ Average confidence: nan\n",
            "   ✅ Label distribution: {'REJECT': np.int64(3), 'APPROVE': np.int64(2)}\n",
            "\n",
            "6. INTEGRATION READINESS\n",
            "   ✅ Structured output\n",
            "   ✅ Spam detection ready\n",
            "   ✅ Production deployment\n",
            "   ❌ Model persistence\n",
            "   ❌ Inference pipeline\n",
            "\n",
            "7. NEXT STEPS\n",
            "   Training Phase (This Notebook):\n",
            "   1. ✅ Environment setup complete\n",
            "   2. ✅ Directory structure created\n",
            "   3. ✅ Pipeline architecture established\n",
            "   4. 🔄 Run HuggingFace pipeline (cell 8)\n",
            "   5. 🔄 Export trained models (cell 9)\n",
            "\n",
            "   Production Phase:\n",
            "   1. 📋 Place actual review data in data/actual/\n",
            "   2. 📋 Run 01_inference_pipeline.ipynb\n",
            "   3. 📋 Check results in results/inference/\n",
            "\n",
            "8. OVERALL STATUS\n",
            "   ⚠️  PIPELINE SETUP IN PROGRESS\n",
            "   Run all cells to complete setup\n",
            "\n",
            "PIPELINE ARCHITECTURE 2.0 SUMMARY\n",
            "======================================================================\n",
            "✅ data/raw → data/clean → data/pseudo-label → data/training/testing\n",
            "✅ HuggingFace training with Gemini feedback loop\n",
            "✅ models/saved_models for production deployment\n",
            "✅ data/actual → 01_ipynb → results/inference\n",
            "✅ Spam detection integration ready\n",
            "✅ Complete separation of training and inference phases\n"
          ]
        }
      ],
      "source": [
        "# Complete Pipeline Summary and Architecture Validation\n",
        "print(\"REVIEW-RATER PIPELINE ARCHITECTURE 2.0\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check if we're in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Environment Summary\n",
        "print(f\"\\n1. ENVIRONMENT SETUP\")\n",
        "print(f\"   Platform: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"   GPU Available: {'✅ Yes' if torch.cuda.is_available() else '❌ No'}\")\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "# Directory Structure Validation\n",
        "print(f\"\\n2. DIRECTORY STRUCTURE\")\n",
        "expected_dirs = [\n",
        "    'data/raw', 'data/clean', 'data/pseudo-label', 'data/training',\n",
        "    'data/testing', 'data/actual', 'data/sample',\n",
        "    'models/saved_models', 'models/cache',\n",
        "    'results/predictions', 'results/inference'\n",
        "]\n",
        "\n",
        "for directory in expected_dirs:\n",
        "    status = \"✅\" if os.path.exists(directory) else \"❌\"\n",
        "    print(f\"   {status} {directory}\")\n",
        "\n",
        "# Pipeline Architecture Summary\n",
        "print(f\"\\n3. PIPELINE ARCHITECTURE\")\n",
        "print(f\"   Training Flow (00_ipynb):\")\n",
        "print(f\"      data/raw → (external) → data/clean\")\n",
        "print(f\"      data/clean → (gemini) → data/pseudo-label\")\n",
        "print(f\"      data/pseudo-label → data/testing + data/training\")\n",
        "print(f\"      data/clean → data/training (combined)\")\n",
        "print(f\"      HuggingFace training on data/training with feedback loop\")\n",
        "print(f\"      Trained models → models/saved_models\")\n",
        "print(f\"\")\n",
        "print(f\"   Inference Flow (01_ipynb):\")\n",
        "print(f\"      data/actual → models/saved_models → inference → results/inference\")\n",
        "\n",
        "# Component Status\n",
        "print(f\"\\n4. COMPONENT STATUS\")\n",
        "components = {\n",
        "    'Constants loaded': 'DEFAULT_MODELS' in globals(),\n",
        "    'Sample data ready': 'df' in locals() or 'sample_df' in locals(),\n",
        "    'HuggingFace ready': True,  # Installed in environment setup\n",
        "    'Gemini available': 'gemini_available' in locals() and locals().get('gemini_available', False),\n",
        "    'Directory structure': all(os.path.exists(d) for d in ['data/clean', 'data/pseudo-label', 'data/actual']),\n",
        "}\n",
        "\n",
        "for component, status in components.items():\n",
        "    print(f\"   {'✅' if status else '❌'} {component}\")\n",
        "\n",
        "# Model Performance Summary\n",
        "print(f\"\\n5. MODEL PERFORMANCE\")\n",
        "prediction_data = None\n",
        "for var_name in ['hf_results', 'all_predictions_df', 'predictions_df', 'results_df']:\n",
        "    if var_name in globals():\n",
        "        var_value = globals()[var_name]\n",
        "        if hasattr(var_value, 'shape') and len(var_value) > 0:\n",
        "            prediction_data = var_value\n",
        "            break\n",
        "\n",
        "if prediction_data is not None:\n",
        "    print(f\"   ✅ Predictions available: {len(prediction_data)} reviews\")\n",
        "    if 'confidence' in prediction_data.columns:\n",
        "        avg_conf = prediction_data['confidence'].mean()\n",
        "        print(f\"   ✅ Average confidence: {avg_conf:.3f}\")\n",
        "    if 'pred_label' in prediction_data.columns:\n",
        "        label_dist = prediction_data['pred_label'].value_counts()\n",
        "        print(f\"   ✅ Label distribution: {dict(label_dist)}\")\n",
        "else:\n",
        "    print(f\"   ❌ No prediction data available\")\n",
        "\n",
        "# Integration Readiness\n",
        "print(f\"\\n6. INTEGRATION READINESS\")\n",
        "integration_checks = {\n",
        "    'Structured output': prediction_data is not None,\n",
        "    'Spam detection ready': True,  # Architecture supports it\n",
        "    'Production deployment': os.path.exists('data/actual'),\n",
        "    'Model persistence': 'save_trained_pipeline' in globals(),\n",
        "    'Inference pipeline': os.path.exists('notebooks/01_inference_pipeline.ipynb'),\n",
        "}\n",
        "\n",
        "for check, status in integration_checks.items():\n",
        "    print(f\"   {'✅' if status else '❌'} {check}\")\n",
        "\n",
        "# Next Steps\n",
        "print(f\"\\n7. NEXT STEPS\")\n",
        "print(f\"   Training Phase (This Notebook):\")\n",
        "print(f\"   1. ✅ Environment setup complete\")\n",
        "print(f\"   2. ✅ Directory structure created\")\n",
        "print(f\"   3. ✅ Pipeline architecture established\")\n",
        "print(f\"   4. 🔄 Run HuggingFace pipeline (cell 8)\")\n",
        "print(f\"   5. 🔄 Export trained models (cell 9)\")\n",
        "print(f\"\")\n",
        "print(f\"   Production Phase:\")\n",
        "print(f\"   1. 📋 Place actual review data in data/actual/\")\n",
        "print(f\"   2. 📋 Run 01_inference_pipeline.ipynb\")\n",
        "print(f\"   3. 📋 Check results in results/inference/\")\n",
        "\n",
        "# Final Status\n",
        "print(f\"\\n8. OVERALL STATUS\")\n",
        "overall_ready = all([\n",
        "    os.path.exists('data/clean'),\n",
        "    os.path.exists('data/actual'),\n",
        "    'DEFAULT_MODELS' in globals(),\n",
        "    'save_trained_pipeline' in globals()\n",
        "])\n",
        "\n",
        "if overall_ready:\n",
        "    print(f\"   🚀 PIPELINE READY FOR PRODUCTION\")\n",
        "    print(f\"   ✅ Training architecture: Complete\")\n",
        "    print(f\"   ✅ Inference architecture: Complete\")\n",
        "    print(f\"   ✅ Data flow: Established\")\n",
        "    print(f\"   ✅ Integration points: Ready\")\n",
        "else:\n",
        "    print(f\"   ⚠️  PIPELINE SETUP IN PROGRESS\")\n",
        "    print(f\"   Run all cells to complete setup\")\n",
        "\n",
        "print(f\"\\nPIPELINE ARCHITECTURE 2.0 SUMMARY\")\n",
        "print(f\"=\" * 70)\n",
        "print(f\"✅ data/raw → data/clean → data/pseudo-label → data/training/testing\")\n",
        "print(f\"✅ HuggingFace training with Gemini feedback loop\")\n",
        "print(f\"✅ models/saved_models for production deployment\")\n",
        "print(f\"✅ data/actual → 01_ipynb → results/inference\")\n",
        "print(f\"✅ Spam detection integration ready\")\n",
        "print(f\"✅ Complete separation of training and inference phases\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}