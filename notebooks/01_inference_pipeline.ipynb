{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fbd1d20d",
      "metadata": {
        "id": "fbd1d20d"
      },
      "source": [
        "# Review Classification Pipeline - Inference with HuggingFace Model\n",
        "\n",
        "This notebook uses the fine-tuned HuggingFace model to classify new reviews without retraining.\n",
        "\n",
        "## Requirements\n",
        "1. Run the complete training pipeline first (00_colab_complete_pipeline.ipynb)\n",
        "2. Ensure trained model exists in `models/saved_models/review_classifier_*/`\n",
        "3. Place your review data in `data/actual/` directory\n",
        "4. Data should be in CSV or JSON format with 'id' and 'text' columns\n",
        "\n",
        "## What This Does\n",
        "- Loads fine-tuned HuggingFace model from `models/saved_models/`\n",
        "- Loads auxiliary models (toxicity detection, zero-shot classification)\n",
        "- Combines custom ML predictions with policy violation detection\n",
        "- Processes reviews from `data/actual/`\n",
        "- Outputs comprehensive classification results\n",
        "- Saves results to `results/inference/`\n",
        "\n",
        "## Model Architecture\n",
        "- **Fine-tuned Model**: Custom HuggingFace transformer for review classification\n",
        "- **Policy Detection**: Zero-shot + toxicity analysis for specific violations\n",
        "- **Dual-layer**: Both models vote; REJECT if either flags the review"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69367005",
      "metadata": {
        "id": "69367005"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "529a00ad",
      "metadata": {
        "id": "529a00ad",
        "outputId": "4c3789bd-2caa-4911-ed14-38963cdf643a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Environment setup complete\n",
            "Current directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (if not already installed)\n",
        "!pip install -q transformers torch pandas scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"‚úÖ Environment setup complete\")\n",
        "print(f\"Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f99e80",
      "metadata": {
        "id": "03f99e80"
      },
      "source": [
        "## 2. Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d5b12581",
      "metadata": {
        "id": "d5b12581",
        "outputId": "be1024a9-f424-4136-fce9-2af8d8d46b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHECKING TRAINED MODEL\n",
            "==============================\n",
            "‚úÖ Found trained model: review_classifier_20250830_195222\n",
            "   Checkpoint: checkpoint-93\n",
            "   Model path: models/saved_models/review_classifier_20250830_195222/checkpoint-93\n",
            "   Model files: tokenizer.json, special_tokens_map.json, optimizer.pt, tokenizer_config.json, vocab.txt, scheduler.pt, rng_state.pth, model.safetensors, trainer_state.json, .ipynb_checkpoints, config.json\n",
            "\n",
            "Using model: review_classifier_20250830_195222\n",
            "Using checkpoint: checkpoint-93\n"
          ]
        }
      ],
      "source": [
        "# Check if trained HuggingFace model exists\n",
        "model_dir = 'models/saved_models'\n",
        "\n",
        "print(\"CHECKING TRAINED MODEL\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# Look for HuggingFace model directories (timestamped folders)\n",
        "model_folders = []\n",
        "if os.path.exists(model_dir):\n",
        "    for item in os.listdir(model_dir):\n",
        "        item_path = os.path.join(model_dir, item)\n",
        "        if os.path.isdir(item_path) and item.startswith('review_classifier_'):\n",
        "            # Look for checkpoint subdirectories within the model folder\n",
        "            checkpoint_dirs = [d for d in os.listdir(item_path)\n",
        "                             if os.path.isdir(os.path.join(item_path, d)) and d.startswith('checkpoint-')]\n",
        "\n",
        "            if checkpoint_dirs:\n",
        "                # Use the highest numbered checkpoint\n",
        "                latest_checkpoint = sorted(checkpoint_dirs, key=lambda x: int(x.split('-')[1]))[-1]\n",
        "                checkpoint_path = os.path.join(item_path, latest_checkpoint)\n",
        "\n",
        "                # Check if this checkpoint contains HuggingFace model files\n",
        "                hf_files = ['config.json', 'tokenizer.json', 'tokenizer_config.json']\n",
        "                model_files = ['model.safetensors', 'pytorch_model.bin']  # Either format\n",
        "\n",
        "                has_config = all(os.path.exists(os.path.join(checkpoint_path, f)) for f in hf_files)\n",
        "                has_model = any(os.path.exists(os.path.join(checkpoint_path, f)) for f in model_files)\n",
        "\n",
        "                if has_config and has_model:\n",
        "                    model_folders.append((item, latest_checkpoint))\n",
        "            else:\n",
        "                # Fallback: check if model files are directly in the main folder\n",
        "                hf_files = ['config.json', 'tokenizer.json', 'tokenizer_config.json']\n",
        "                model_files = ['model.safetensors', 'pytorch_model.bin']\n",
        "\n",
        "                has_config = all(os.path.exists(os.path.join(item_path, f)) for f in hf_files)\n",
        "                has_model = any(os.path.exists(os.path.join(item_path, f)) for f in model_files)\n",
        "\n",
        "                if has_config and has_model:\n",
        "                    model_folders.append((item, None))\n",
        "\n",
        "if not model_folders:\n",
        "    print(f\"‚ùå ERROR: No trained HuggingFace model found in {model_dir}\")\n",
        "    print(f\"\\nPlease run the training notebook first:\")\n",
        "    print(f\"1. Open 00_colab_complete_pipeline.ipynb\")\n",
        "    print(f\"2. Run all cells to train the model\")\n",
        "    print(f\"3. Ensure model is saved to models/saved_models/\")\n",
        "    print(f\"4. Then return to this inference notebook\")\n",
        "    sys.exit()\n",
        "else:\n",
        "    # Use the most recent model (last in alphabetical order = most recent timestamp)\n",
        "    latest_model_info = sorted(model_folders)[-1]\n",
        "    latest_model, checkpoint = latest_model_info\n",
        "\n",
        "    if checkpoint:\n",
        "        model_path = os.path.join(model_dir, latest_model, checkpoint)\n",
        "        print(f\"‚úÖ Found trained model: {latest_model}\")\n",
        "        print(f\"   Checkpoint: {checkpoint}\")\n",
        "        print(f\"   Model path: {model_path}\")\n",
        "    else:\n",
        "        model_path = os.path.join(model_dir, latest_model)\n",
        "        print(f\"‚úÖ Found trained model: {latest_model}\")\n",
        "        print(f\"   Model path: {model_path}\")\n",
        "\n",
        "    # Check model files\n",
        "    model_files = os.listdir(model_path)\n",
        "    print(f\"   Model files: {', '.join(model_files)}\")\n",
        "\n",
        "    # Load latest_config.json if it exists for metadata\n",
        "    config_file = os.path.join(model_dir, 'latest_config.json')\n",
        "    if os.path.exists(config_file):\n",
        "        with open(config_file, 'r') as f:\n",
        "            config_metadata = json.load(f)\n",
        "        print(f\"\\nModel Information:\")\n",
        "        print(f\"   Training mode: {config_metadata.get('training_mode', 'Unknown')}\")\n",
        "        print(f\"   Timestamp: {config_metadata.get('timestamp', 'Unknown')}\")\n",
        "        print(f\"   Confidence threshold: {config_metadata.get('confidence_threshold', 0.55)}\")\n",
        "    else:\n",
        "        print(f\"\\nUsing model: {latest_model}\")\n",
        "        if checkpoint:\n",
        "            print(f\"Using checkpoint: {checkpoint}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f98fa2e1",
      "metadata": {
        "id": "f98fa2e1"
      },
      "source": [
        "## 3. Load Inference Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fb3062a5",
      "metadata": {
        "id": "fb3062a5",
        "outputId": "b3c8a3ce-8d7b-4a78-cae8-e9740f109fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING ALL TRAINED MODELS\n",
            "========================================\n",
            "Loading fine-tuned HuggingFace model from: models/saved_models/review_classifier_20250830_195222/checkpoint-93\n",
            "‚úÖ HuggingFace model loaded successfully\n",
            "   Model type: distilbert\n",
            "   Vocab size: 30522\n",
            "\n",
            "Loading spam detector from: /content/models/saved_models/unified_spam_detector_20250830_195222.joblib\n",
            "‚úÖ Spam detector loaded successfully\n",
            "   Spam detector type: UnifiedSpamDetector\n",
            "\n",
            "Device: CPU\n",
            "\n",
            "Loading auxiliary models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Auxiliary models loaded\n",
            "\n",
            "‚úÖ ALL MODELS LOADED SUCCESSFULLY\n",
            "   HuggingFace Model: ‚úÖ Ready\n",
            "   Policy Detection (toxicity + zero-shot): ‚úÖ Ready\n",
            "   Confidence threshold: 0.55\n",
            "\n",
            "üöÄ Triple-layer detection ready for inference!\n"
          ]
        }
      ],
      "source": [
        "# Load ALL trained models: HuggingFace + Spam Detector + Auxiliary models\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import torch\n",
        "import numpy as np\n",
        "import joblib\n",
        "import sys\n",
        "import os\n",
        "\n",
        "print(\"LOADING ALL TRAINED MODELS\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# -------- Safe defaults (in case not previously defined) --------\n",
        "try:\n",
        "    model_path\n",
        "except NameError:\n",
        "    # Set this to where your fine-tuned HF model folder lives (config.json, pytorch_model.bin, tokenizer files)\n",
        "    model_path = \"/content/models/saved_models\"  # <-- change if needed\n",
        "\n",
        "try:\n",
        "    model_dir\n",
        "except NameError:\n",
        "    model_dir = \"/content/models\"  # not strictly needed now, but kept for consistency\n",
        "\n",
        "try:\n",
        "    config_metadata\n",
        "except NameError:\n",
        "    config_metadata = {}\n",
        "\n",
        "# Exact path to spam detector .joblib (as requested)\n",
        "SPAM_MODEL_PATH = \"/content/models/saved_models/unified_spam_detector_20250830_195222.joblib\"\n",
        "\n",
        "try:\n",
        "    # 1) Load the fine-tuned HuggingFace model\n",
        "    print(f\"Loading fine-tuned HuggingFace model from: {model_path}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    hf_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    print(f\"‚úÖ HuggingFace model loaded successfully\")\n",
        "    print(f\"   Model type: {hf_model.config.model_type}\")\n",
        "    # Some tokenizers (e.g., sentencepiece) may not have vocab_size; guard it:\n",
        "    vocab_size = getattr(tokenizer, \"vocab_size\", None)\n",
        "    print(f\"   Vocab size: {vocab_size if vocab_size is not None else 'N/A'}\")\n",
        "\n",
        "    # 2) Load the spam detector model (direct path)\n",
        "    print(f\"\\nLoading spam detector from: {SPAM_MODEL_PATH}\")\n",
        "    try:\n",
        "        spam_detector = joblib.load(SPAM_MODEL_PATH)\n",
        "        print(f\"‚úÖ Spam detector loaded successfully\")\n",
        "        print(f\"   Spam detector type: {type(spam_detector).__name__}\")\n",
        "        spam_model_available = True\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Spam detector file not found at: {SPAM_MODEL_PATH}\")\n",
        "        spam_model_available = False\n",
        "        spam_detector = None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error loading spam detector: {e}\")\n",
        "        spam_model_available = False\n",
        "        spam_detector = None\n",
        "\n",
        "    # 3) Load auxiliary models for policy detection\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    print(f\"\\nDevice: {'GPU' if device == 0 else 'CPU'}\")\n",
        "\n",
        "    print(f\"\\nLoading auxiliary models...\")\n",
        "    # Toxicity classification pipeline\n",
        "    toxic_pipeline = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=\"unitary/toxic-bert\",\n",
        "        top_k=None,\n",
        "        device=device\n",
        "    )\n",
        "    # Zero-shot classification pipeline\n",
        "    zshot_pipeline = pipeline(\n",
        "        \"zero-shot-classification\",\n",
        "        model=\"facebook/bart-large-mnli\",\n",
        "        device=device\n",
        "    )\n",
        "    print(f\"‚úÖ Auxiliary models loaded\")\n",
        "\n",
        "    # 4) Constants for labels/policies\n",
        "    POLICY_CATEGORIES = {\n",
        "        'NO_ADS': 'No_Ads',\n",
        "        'IRRELEVANT': 'Irrelevant',\n",
        "        'RANT_NO_VISIT': 'Rant_No_Visit',\n",
        "        'NONE': 'None'\n",
        "    }\n",
        "\n",
        "    LABELS = {\n",
        "        'APPROVE': 'APPROVE',\n",
        "        'REJECT': 'REJECT'\n",
        "    }\n",
        "\n",
        "    ZERO_SHOT_LABELS = [\n",
        "        \"an advertisement or promotional solicitation for this business (promo code, referral, links, contact to buy)\",\n",
        "        \"off-topic or unrelated to this business (e.g., politics, crypto, chain messages, personal stories not about this place)\",\n",
        "        \"a generic negative rant about this business without evidence of a visit (short insults, 'scam', 'overpriced', 'worst ever')\",\n",
        "        \"a relevant on-topic description of a visit or experience at this business\"\n",
        "    ]\n",
        "\n",
        "    ZERO_SHOT_TO_POLICY = {\n",
        "        ZERO_SHOT_LABELS[0]: POLICY_CATEGORIES['NO_ADS'],\n",
        "        ZERO_SHOT_LABELS[1]: POLICY_CATEGORIES['IRRELEVANT'],\n",
        "        ZERO_SHOT_LABELS[2]: POLICY_CATEGORIES['RANT_NO_VISIT'],\n",
        "        ZERO_SHOT_LABELS[3]: POLICY_CATEGORIES['NONE']\n",
        "    }\n",
        "\n",
        "    # 5) Confidence threshold\n",
        "    confidence_threshold = config_metadata.get('confidence_threshold', 0.55)\n",
        "\n",
        "    print(f\"\\n‚úÖ ALL MODELS LOADED SUCCESSFULLY\")\n",
        "    print(f\"   HuggingFace Model: ‚úÖ Ready\")\n",
        "    print(f\"   Policy Detection (toxicity + zero-shot): ‚úÖ Ready\")\n",
        "    print(f\"   Confidence threshold: {confidence_threshold}\")\n",
        "    print(f\"\\nüöÄ Triple-layer detection ready for inference!\")\n",
        "\n",
        "    models_loaded = True\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading models: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    print(f\"\\nTroubleshooting:\")\n",
        "    print(f\"1. Ensure the training notebook completed successfully\")\n",
        "    print(f\"2. Check that model files exist in: {model_path}\")\n",
        "    print(f\"3. Verify spam detector exists at: {SPAM_MODEL_PATH}\")\n",
        "    print(f\"4. Verify internet connection for downloading auxiliary models\")\n",
        "    models_loaded = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b42dab9",
      "metadata": {
        "id": "6b42dab9"
      },
      "source": [
        "## 4. Load Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7c6c3a06",
      "metadata": {
        "id": "7c6c3a06",
        "outputId": "20330f64-35a9-457e-feb2-338365665719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING INPUT DATA\n",
            "=========================\n",
            "Available input files in data/actual:\n",
            "   test_reviews.csv (1422 bytes)\n",
            "\n",
            "Choose a file to process:\n",
            "   1. test_reviews.csv\n",
            "\n",
            "Using: test_reviews.csv\n",
            "‚úÖ Data loaded successfully\n",
            "   Reviews to process: 15\n",
            "   Columns: ['id', 'text']\n",
            "\n",
            "Data Preview:\n",
            "   ID 1: Great food and excellent service! Will definitely come back.\n",
            "   ID 2: Use my promo code SAVE20 for 20% off your next order! DM me ...\n",
            "   ID 3: Bitcoin is going to the moon! Buy now before it's too late!\n",
            "   ... and 12 more reviews\n"
          ]
        }
      ],
      "source": [
        "# Check for input data in data/actual directory\n",
        "input_dir = 'data/actual'\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "print(\"LOADING INPUT DATA\")\n",
        "print(\"=\"*25)\n",
        "\n",
        "# Look for CSV and JSON files\n",
        "input_files = []\n",
        "if os.path.exists(input_dir):\n",
        "    for file in os.listdir(input_dir):\n",
        "        if file.endswith(('.csv', '.json')):\n",
        "            input_files.append(file)\n",
        "\n",
        "print(f\"Available input files in {input_dir}:\")\n",
        "for file in input_files:\n",
        "    file_path = os.path.join(input_dir, file)\n",
        "    file_size = os.path.getsize(file_path)\n",
        "    print(f\"   {file} ({file_size} bytes)\")\n",
        "\n",
        "if not input_files:\n",
        "    print(f\"‚ùå No input files found in {input_dir}\")\n",
        "    print(f\"\\nTo add your review data:\")\n",
        "    print(f\"1. Create a CSV file with columns: 'id', 'text'\")\n",
        "    print(f\"2. Or create a JSON file with array of objects: [{'id': 1, 'text': 'review text'}, ...]\")\n",
        "    print(f\"3. Place the file in {input_dir}\")\n",
        "    print(f\"4. Re-run this cell\")\n",
        "    print(f\"\\nExample files are already created for you to test with.\")\n",
        "\n",
        "# Let user choose which file to process\n",
        "if input_files:\n",
        "    print(f\"\\nChoose a file to process:\")\n",
        "    for i, file in enumerate(input_files):\n",
        "        print(f\"   {i+1}. {file}\")\n",
        "\n",
        "    # For demo, automatically use the first file\n",
        "    # In practice, you might want to manually specify the file\n",
        "    selected_file = input_files[0]\n",
        "    print(f\"\\nUsing: {selected_file}\")\n",
        "\n",
        "    # Load the selected file\n",
        "    file_path = os.path.join(input_dir, selected_file)\n",
        "\n",
        "    try:\n",
        "        if selected_file.endswith('.csv'):\n",
        "            input_data = pd.read_csv(file_path)\n",
        "        elif selected_file.endswith('.json'):\n",
        "            with open(file_path, 'r') as f:\n",
        "                json_data = json.load(f)\n",
        "            input_data = pd.DataFrame(json_data)\n",
        "\n",
        "        # Validate required columns\n",
        "        if 'text' not in input_data.columns:\n",
        "            print(f\"‚ùå Missing required 'text' column\")\n",
        "            print(f\"Available columns: {list(input_data.columns)}\")\n",
        "            input_data = None\n",
        "        else:\n",
        "            # Add ID column if missing\n",
        "            if 'id' not in input_data.columns:\n",
        "                input_data['id'] = range(1, len(input_data) + 1)\n",
        "\n",
        "            print(f\"‚úÖ Data loaded successfully\")\n",
        "            print(f\"   Reviews to process: {len(input_data)}\")\n",
        "            print(f\"   Columns: {list(input_data.columns)}\")\n",
        "\n",
        "            # Show preview\n",
        "            print(f\"\\nData Preview:\")\n",
        "            for idx, row in input_data.head(3).iterrows():\n",
        "                text_preview = str(row['text'])[:60] + \"...\" if len(str(row['text'])) > 60 else str(row['text'])\n",
        "                print(f\"   ID {row['id']}: {text_preview}\")\n",
        "\n",
        "            if len(input_data) > 3:\n",
        "                print(f\"   ... and {len(input_data) - 3} more reviews\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading file: {e}\")\n",
        "        input_data = None\n",
        "else:\n",
        "    input_data = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f63525ac",
      "metadata": {
        "id": "f63525ac"
      },
      "source": [
        "## 5. Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b378154b",
      "metadata": {
        "id": "b378154b",
        "outputId": "6ed3dbae-3d30-4a1a-9cfc-2a8fecb41d15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNNING INFERENCE\n",
            "====================\n",
            "Processing 15 reviews...\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "Warning: Spam detector error: X has 5005 features, but LogisticRegression is expecting 5011 features as input.\n",
            "‚úÖ Inference completed!\n",
            "   Processed: 15 reviews\n",
            "\n",
            "RESULTS SUMMARY\n",
            "====================\n",
            "Total reviews: 15\n",
            "APPROVE: 11 (73.3%)\n",
            "REJECT: 4 (26.7%)\n",
            "Average confidence: 0.749\n",
            "\n",
            "REJECT Categories:\n",
            "   Rant_No_Visit: 3 reviews\n",
            "   No_Ads: 1 reviews\n",
            "\n",
            "DETECTION LAYER ANALYSIS:\n",
            "   Clean (0 layers flagged): 11 reviews\n",
            "   Flagged by 1 layer(s): 4 reviews\n",
            "\n",
            "MODEL-SPECIFIC DETECTIONS:\n",
            "   HuggingFace Model: 0 rejections\n",
            "   Spam Detector: 0 rejections\n",
            "   Policy Detection: 4 rejections\n",
            "\n",
            "DETAILED RESULTS\n",
            "======================================================================\n",
            " id                                        text pred_label pred_category  confidence  detection_layers\n",
            "  1 Great food and excellent service! Will d...    APPROVE          None      0.7313                 0\n",
            "  2 Use my promo code SAVE20 for 20% off you...     REJECT        No_Ads      0.8000                 1\n",
            "  3 Bitcoin is going to the moon! Buy now be...    APPROVE          None      0.7286                 0\n",
            "  4 Terrible place, worst food ever, total s...     REJECT Rant_No_Visit      0.8000                 1\n",
            "  5 Had dinner here last night, the pasta wa...    APPROVE          None      0.7315                 0\n",
            "  6 Visited on Friday evening with family. T...    APPROVE          None      0.7316                 0\n",
            "  7 Check out my website www.bestdeals.com f...    APPROVE          None      0.7305                 0\n",
            "  8 The government is corrupt and politician...     REJECT Rant_No_Visit      0.8000                 1\n",
            "  9 Overpriced garbage. Never going back. Co...     REJECT Rant_No_Visit      0.8000                 1\n",
            " 10 Made a reservation for 6pm, got seated p...    APPROVE          None      0.7311                 0\n",
            " 11 Food is good food is great food is nice ...    APPROVE          None      0.7317                 0\n",
            " 12 WhatsApp me at +1234567890 for special g...    APPROVE          None      0.7310                 0\n",
            " 13 The climate change hoax is destroying sm...    APPROVE          None      0.7309                 0\n",
            " 14 Awful service, rude staff, terrible mana...    APPROVE          None      0.7315                 0\n",
            " 15 Celebrated my anniversary here last mont...    APPROVE          None      0.7317                 0\n",
            "\n",
            "‚úÖ Results saved to: results/inference/inference_results_20250830_214431.csv\n",
            "\n",
            "SUCCESS: Inference complete!\n",
            "Your reviews have been classified for policy violations.\n"
          ]
        }
      ],
      "source": [
        "# Define the inference functions\n",
        "def predict_with_hf_model(text, model, tokenizer):\n",
        "    \"\"\"Predict using fine-tuned HuggingFace model\"\"\"\n",
        "    inputs = tokenizer(text, truncation=True, padding=True, max_length=256, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        conf = float(probs.max())\n",
        "        pred = int(probs.argmax())\n",
        "    return (\"REJECT\" if pred == 1 else \"APPROVE\"), conf\n",
        "\n",
        "def predict_with_spam_detector(text, spam_detector):\n",
        "    \"\"\"Predict using spam detector model\"\"\"\n",
        "    if spam_detector is None:\n",
        "        return \"APPROVE\", 0.5, \"None\"\n",
        "\n",
        "    try:\n",
        "        results = spam_detector.predict([text])\n",
        "        result = results[0]\n",
        "        return result.label, result.confidence, result.category\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Spam detector error: {e}\")\n",
        "        return \"APPROVE\", 0.5, \"None\"\n",
        "\n",
        "def tox_top_label(tox_output):\n",
        "    \"\"\"Extract top toxicity label and score\"\"\"\n",
        "    try:\n",
        "        if isinstance(tox_output, dict):\n",
        "            candidates = [tox_output]\n",
        "        elif isinstance(tox_output, list):\n",
        "            if len(tox_output) and isinstance(tox_output[0], dict):\n",
        "                candidates = tox_output\n",
        "            elif len(tox_output) and isinstance(tox_output[0], list):\n",
        "                candidates = tox_output[0]\n",
        "            else:\n",
        "                candidates = []\n",
        "        else:\n",
        "            candidates = []\n",
        "        if not candidates:\n",
        "            return \"NONE\", 0.0\n",
        "        best = max(candidates, key=lambda d: float(d.get(\"score\", 0.0)))\n",
        "        return best.get(\"label\", \"NONE\"), float(best.get(\"score\", 0.0))\n",
        "    except Exception:\n",
        "        return \"NONE\", 0.0\n",
        "\n",
        "def policy_zero_shot_fused(zshot, toxic, text, tau_irrelevant=0.55, tau_rant=0.55, tau_ads=0.70, tox_tau=0.50):\n",
        "    \"\"\"Unified policy detection using zero-shot + toxicity\"\"\"\n",
        "    # Zero-shot classification\n",
        "    zs_res = zshot(text, candidate_labels=ZERO_SHOT_LABELS,\n",
        "                   hypothesis_template=\"This review is {}.\", multi_label=True)\n",
        "    zs = {lab: float(scr) for lab, scr in zip(zs_res[\"labels\"], zs_res[\"scores\"])}\n",
        "\n",
        "    ads = zs.get(ZERO_SHOT_LABELS[0], 0.0)\n",
        "    irr = zs.get(ZERO_SHOT_LABELS[1], 0.0)\n",
        "    rant = zs.get(ZERO_SHOT_LABELS[2], 0.0)\n",
        "\n",
        "    # Toxicity gate\n",
        "    tox_label, tox_score = tox_top_label(toxic(text))\n",
        "\n",
        "    TOX_TO_RANT = {\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\"}\n",
        "    TOX_TO_IRRELEVANT = {\"identity_hate\"}\n",
        "\n",
        "    if tox_label and tox_score >= tox_tau:\n",
        "        if tox_label in TOX_TO_RANT:\n",
        "            return LABELS['REJECT'], POLICY_CATEGORIES['RANT_NO_VISIT']\n",
        "        if tox_label in TOX_TO_IRRELEVANT:\n",
        "            return LABELS['REJECT'], POLICY_CATEGORIES['IRRELEVANT']\n",
        "\n",
        "    # Policy thresholds\n",
        "    if max(irr, rant) >= min(tau_irrelevant, tau_rant):\n",
        "        return LABELS['REJECT'], (POLICY_CATEGORIES['IRRELEVANT'] if irr >= rant else POLICY_CATEGORIES['RANT_NO_VISIT'])\n",
        "\n",
        "    # Ads detection with evidence\n",
        "    import re\n",
        "    AD_PATTERNS = [r\"https?://\", r\"\\bwww\\.\", r\"\\.[a-z]{2,6}\\b\", r\"\\b(?:\\+?\\d[\\s\\-()]*){7,}\\b\",\n",
        "                   r\"\\bpromo(?:\\s*code)?\\b\", r\"\\bdiscount\\b\", r\"\\bcoupon\\b\", r\"\\breferral\\b\",\n",
        "                   r\"\\buse\\s*code\\b\", r\"\\bwhatsapp\\b\", r\"\\bdm\\s+(?:me|us)\\b\"]\n",
        "    AD_REGEX = re.compile(\"|\".join(AD_PATTERNS), flags=re.IGNORECASE)\n",
        "\n",
        "    has_ads = bool(AD_REGEX.search(text))\n",
        "    ads_margin = 0.10\n",
        "\n",
        "    if has_ads and (ads >= tau_ads) and (ads >= max(irr, rant) + ads_margin):\n",
        "        return LABELS['REJECT'], POLICY_CATEGORIES['NO_ADS']\n",
        "\n",
        "    return LABELS['APPROVE'], POLICY_CATEGORIES['NONE']\n",
        "\n",
        "def process_reviews(input_df):\n",
        "    \"\"\"Process reviews using ALL three detection layers: HF Model + Spam Detector + Policy Detection\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for _, row in input_df.iterrows():\n",
        "        text = str(row['text'])\n",
        "\n",
        "        # Layer 1: HuggingFace fine-tuned model\n",
        "        hf_label, hf_conf = predict_with_hf_model(text, hf_model, tokenizer)\n",
        "\n",
        "        # Layer 2: Spam detector (pattern + ML analysis)\n",
        "        spam_label, spam_conf, spam_category = predict_with_spam_detector(text, spam_detector)\n",
        "\n",
        "        # Layer 3: Policy detection for specific violations\n",
        "        policy_label, policy_category = policy_zero_shot_fused(\n",
        "            zshot_pipeline, toxic_pipeline, text,\n",
        "            tau_irrelevant=0.55, tau_rant=0.55, tau_ads=0.70, tox_tau=0.50\n",
        "        )\n",
        "\n",
        "        # Triple-layer decision logic: ANY layer can reject\n",
        "        rejection_reasons = []\n",
        "        final_confidence = 0.7  # Default\n",
        "\n",
        "        if hf_label == 'REJECT':\n",
        "            rejection_reasons.append(('HuggingFace_ML', hf_conf))\n",
        "\n",
        "        if spam_label == 'REJECT':\n",
        "            rejection_reasons.append(('Spam_Detection', spam_conf))\n",
        "\n",
        "        if policy_label == 'REJECT':\n",
        "            rejection_reasons.append(('Policy_Violation', 0.8))\n",
        "\n",
        "        # Final decision\n",
        "        if rejection_reasons:\n",
        "            final_label = 'REJECT'\n",
        "            # Use the highest confidence rejection reason\n",
        "            best_reason, best_conf = max(rejection_reasons, key=lambda x: x[1])\n",
        "\n",
        "            if best_reason == 'Policy_Violation':\n",
        "                final_category = policy_category\n",
        "                final_confidence = 0.8\n",
        "            elif best_reason == 'Spam_Detection':\n",
        "                final_category = spam_category if spam_category != 'None' else 'Spam_Detected'\n",
        "                final_confidence = spam_conf\n",
        "            else:  # HuggingFace\n",
        "                final_category = 'HF_ML_Detected'\n",
        "                final_confidence = hf_conf\n",
        "        else:\n",
        "            final_label = 'APPROVE'\n",
        "            final_category = 'None'\n",
        "            # Use average confidence of all models for approval\n",
        "            final_confidence = (hf_conf + spam_conf + 0.7) / 3\n",
        "\n",
        "        results.append({\n",
        "            'id': row['id'],\n",
        "            'text': text,\n",
        "            'pred_label': final_label,\n",
        "            'pred_category': final_category,\n",
        "            'confidence': round(final_confidence, 4),\n",
        "            # Layer-specific results for analysis\n",
        "            'hf_label': hf_label,\n",
        "            'hf_confidence': round(hf_conf, 4),\n",
        "            'spam_label': spam_label,\n",
        "            'spam_confidence': round(spam_conf, 4),\n",
        "            'spam_category': spam_category,\n",
        "            'policy_label': policy_label,\n",
        "            'policy_category': policy_category,\n",
        "            'detection_layers': len(rejection_reasons)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Run inference if everything is ready\n",
        "if models_loaded and input_data is not None and len(input_data) > 0:\n",
        "\n",
        "    print(\"RUNNING INFERENCE\")\n",
        "    print(\"=\"*20)\n",
        "    print(f\"Processing {len(input_data)} reviews...\")\n",
        "\n",
        "    try:\n",
        "        # Run the inference\n",
        "        results = process_reviews(input_data)\n",
        "\n",
        "        print(f\"‚úÖ Inference completed!\")\n",
        "        print(f\"   Processed: {len(results)} reviews\")\n",
        "\n",
        "        # Create results directory\n",
        "        results_dir = 'results/inference'\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "        # Save results\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        results_file = f\"inference_results_{timestamp}.csv\"\n",
        "        results_path = os.path.join(results_dir, results_file)\n",
        "\n",
        "        results.to_csv(results_path, index=False)\n",
        "\n",
        "        print(f\"\\nRESULTS SUMMARY\")\n",
        "        print(\"=\"*20)\n",
        "\n",
        "        # Summary statistics\n",
        "        approve_count = len(results[results['pred_label'] == 'APPROVE'])\n",
        "        reject_count = len(results[results['pred_label'] == 'REJECT'])\n",
        "        avg_confidence = results['confidence'].mean()\n",
        "\n",
        "        print(f\"Total reviews: {len(results)}\")\n",
        "        print(f\"APPROVE: {approve_count} ({approve_count/len(results)*100:.1f}%)\")\n",
        "        print(f\"REJECT: {reject_count} ({reject_count/len(results)*100:.1f}%)\")\n",
        "        print(f\"Average confidence: {avg_confidence:.3f}\")\n",
        "\n",
        "        # Category breakdown for rejected reviews\n",
        "        if reject_count > 0:\n",
        "            print(f\"\\nREJECT Categories:\")\n",
        "            reject_categories = results[results['pred_label'] == 'REJECT']['pred_category'].value_counts()\n",
        "            for category, count in reject_categories.items():\n",
        "                print(f\"   {category}: {count} reviews\")\n",
        "\n",
        "        # Layer analysis\n",
        "        print(f\"\\nDETECTION LAYER ANALYSIS:\")\n",
        "        layer_counts = results['detection_layers'].value_counts().sort_index()\n",
        "        for layers, count in layer_counts.items():\n",
        "            if layers == 0:\n",
        "                print(f\"   Clean (0 layers flagged): {count} reviews\")\n",
        "            else:\n",
        "                print(f\"   Flagged by {layers} layer(s): {count} reviews\")\n",
        "\n",
        "        # Model agreement analysis\n",
        "        hf_rejects = len(results[results['hf_label'] == 'REJECT'])\n",
        "        spam_rejects = len(results[results['spam_label'] == 'REJECT']) if spam_model_available else 0\n",
        "        policy_rejects = len(results[results['policy_label'] == 'REJECT'])\n",
        "\n",
        "        print(f\"\\nMODEL-SPECIFIC DETECTIONS:\")\n",
        "        print(f\"   HuggingFace Model: {hf_rejects} rejections\")\n",
        "        if spam_model_available:\n",
        "            print(f\"   Spam Detector: {spam_rejects} rejections\")\n",
        "        else:\n",
        "            print(f\"   Spam Detector: Not available\")\n",
        "        print(f\"   Policy Detection: {policy_rejects} rejections\")\n",
        "\n",
        "        # Show detailed results\n",
        "        print(f\"\\nDETAILED RESULTS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        display_df = results.copy()\n",
        "        # Truncate text for display\n",
        "        display_df['text'] = display_df['text'].apply(lambda x: x[:40] + \"...\" if len(x) > 40 else x)\n",
        "\n",
        "        display_cols = ['id', 'text', 'pred_label', 'pred_category', 'confidence', 'detection_layers']\n",
        "        print(display_df[display_cols].to_string(index=False))\n",
        "\n",
        "        print(f\"\\n‚úÖ Results saved to: {results_path}\")\n",
        "        print(f\"\\nSUCCESS: Inference complete!\")\n",
        "        print(f\"Your reviews have been classified for policy violations.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during inference: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot run inference\")\n",
        "    if not models_loaded:\n",
        "        print(\"   Models not loaded properly\")\n",
        "    if input_data is None or len(input_data) == 0:\n",
        "        print(\"   No input data available\")\n",
        "\n",
        "    print(f\"\\nPlease check:\")\n",
        "    print(f\"1. Training notebook was run successfully\")\n",
        "    print(f\"2. Input data is placed in data/actual/ directory\")\n",
        "    print(f\"3. Input data has required 'text' column\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16c18b38",
      "metadata": {
        "id": "16c18b38"
      },
      "source": [
        "## 6. Results Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dea4afe0",
      "metadata": {
        "id": "dea4afe0",
        "outputId": "20449a98-2d19-49fa-b4ee-763906654346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADVANCED RESULTS ANALYSIS\n",
            "==============================\n",
            "Confidence Distribution:\n",
            "   High (‚â•0.8): 4 reviews (26.7%)\n",
            "   Medium (0.6-0.8): 11 reviews (73.3%)\n",
            "   Low (<0.6): 0 reviews (0.0%)\n",
            "\n",
            "Policy Violation Types:\n",
            "   None: 11 reviews (73.3%) - Clean Review\n",
            "   Rant_No_Visit: 3 reviews (20.0%) - Policy Violation\n",
            "   No_Ads: 1 reviews (6.7%) - Policy Violation\n",
            "\n",
            "HIGH-RISK REVIEWS (High confidence violations):\n",
            "   ID 2: No_Ads (0.800) - Use my promo code SAVE20 for 20% off your next order! DM me ...\n",
            "   ID 4: Rant_No_Visit (0.800) - Terrible place, worst food ever, total scam and ripoff.\n",
            "   ID 8: Rant_No_Visit (0.800) - The government is corrupt and politicians are ruining this c...\n",
            "   ID 9: Rant_No_Visit (0.800) - Overpriced garbage. Never going back. Complete waste of mone...\n",
            "\n",
            "‚úÖ Summary report saved: results/inference/summary_report_20250830_214431.json\n",
            "\n",
            "INFERENCE COMPLETE\n",
            "Files created:\n",
            "   results/inference/inference_results_20250830_214431.csv - Detailed results\n",
            "   results/inference/summary_report_20250830_214431.json - Summary report\n"
          ]
        }
      ],
      "source": [
        "# Advanced analysis of results (if available)\n",
        "if 'results' in locals() and len(results) > 0:\n",
        "\n",
        "    print(\"ADVANCED RESULTS ANALYSIS\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    # Confidence distribution\n",
        "    high_conf = results[results['confidence'] >= 0.8]\n",
        "    medium_conf = results[(results['confidence'] >= 0.6) & (results['confidence'] < 0.8)]\n",
        "    low_conf = results[results['confidence'] < 0.6]\n",
        "\n",
        "    print(f\"Confidence Distribution:\")\n",
        "    print(f\"   High (‚â•0.8): {len(high_conf)} reviews ({len(high_conf)/len(results)*100:.1f}%)\")\n",
        "    print(f\"   Medium (0.6-0.8): {len(medium_conf)} reviews ({len(medium_conf)/len(results)*100:.1f}%)\")\n",
        "    print(f\"   Low (<0.6): {len(low_conf)} reviews ({len(low_conf)/len(results)*100:.1f}%)\")\n",
        "\n",
        "    # Policy violations by type\n",
        "    print(f\"\\nPolicy Violation Types:\")\n",
        "    category_counts = results['pred_category'].value_counts()\n",
        "    for category, count in category_counts.items():\n",
        "        percentage = count / len(results) * 100\n",
        "        status = \"Policy Violation\" if category != \"None\" else \"Clean Review\"\n",
        "        print(f\"   {category}: {count} reviews ({percentage:.1f}%) - {status}\")\n",
        "\n",
        "    # Flag high-risk reviews\n",
        "    high_risk = results[\n",
        "        (results['pred_label'] == 'REJECT') &\n",
        "        (results['confidence'] >= 0.8)\n",
        "    ]\n",
        "\n",
        "    if len(high_risk) > 0:\n",
        "        print(f\"\\nHIGH-RISK REVIEWS (High confidence violations):\")\n",
        "        for idx, row in high_risk.iterrows():\n",
        "            text_preview = row['text'][:60] + \"...\" if len(row['text']) > 60 else row['text']\n",
        "            print(f\"   ID {row['id']}: {row['pred_category']} ({row['confidence']:.3f}) - {text_preview}\")\n",
        "\n",
        "    # Export summary report\n",
        "    summary_report = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'total_reviews': len(results),\n",
        "        'approve_count': len(results[results['pred_label'] == 'APPROVE']),\n",
        "        'reject_count': len(results[results['pred_label'] == 'REJECT']),\n",
        "        'average_confidence': float(results['confidence'].mean()),\n",
        "        'high_confidence_count': len(high_conf),\n",
        "        'category_breakdown': category_counts.to_dict(),\n",
        "        'high_risk_reviews': len(high_risk)\n",
        "    }\n",
        "\n",
        "    summary_path = os.path.join(results_dir, f\"summary_report_{timestamp}.json\")\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(summary_report, f, indent=2)\n",
        "\n",
        "    print(f\"\\n‚úÖ Summary report saved: {summary_path}\")\n",
        "\n",
        "    print(f\"\\nINFERENCE COMPLETE\")\n",
        "    print(f\"Files created:\")\n",
        "    print(f\"   {results_path} - Detailed results\")\n",
        "    print(f\"   {summary_path} - Summary report\")\n",
        "\n",
        "else:\n",
        "    print(\"No results available for analysis\")\n",
        "    print(\"Run the inference cell first to generate results\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}